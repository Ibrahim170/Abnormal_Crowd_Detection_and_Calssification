{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nnp.random.seed(333)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-30T23:52:59.805689Z","iopub.execute_input":"2021-12-30T23:52:59.805966Z","iopub.status.idle":"2021-12-30T23:52:59.811718Z","shell.execute_reply.started":"2021-12-30T23:52:59.805936Z","shell.execute_reply":"2021-12-30T23:52:59.810475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:00.091186Z","iopub.execute_input":"2021-12-30T23:53:00.091516Z","iopub.status.idle":"2021-12-30T23:53:23.308915Z","shell.execute_reply.started":"2021-12-30T23:53:00.091463Z","shell.execute_reply":"2021-12-30T23:53:23.307708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gdrive_folder_link=\"https://drive.google.com/drive/folders/1RpD6itBuWYCdFeTjVilt9CKPgDvqoitq?usp=sharing\"","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:23.311245Z","iopub.execute_input":"2021-12-30T23:53:23.31153Z","iopub.status.idle":"2021-12-30T23:53:23.316915Z","shell.execute_reply.started":"2021-12-30T23:53:23.31148Z","shell.execute_reply":"2021-12-30T23:53:23.315759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\ngdown.download_folder(gdrive_folder_link, quiet=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:23.318451Z","iopub.execute_input":"2021-12-30T23:53:23.318793Z","iopub.status.idle":"2021-12-30T23:53:34.905851Z","shell.execute_reply.started":"2021-12-30T23:53:23.318759Z","shell.execute_reply":"2021-12-30T23:53:34.904566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport time\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:34.908734Z","iopub.execute_input":"2021-12-30T23:53:34.909052Z","iopub.status.idle":"2021-12-30T23:53:35.105444Z","shell.execute_reply.started":"2021-12-30T23:53:34.909012Z","shell.execute_reply":"2021-12-30T23:53:35.104469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:35.106841Z","iopub.execute_input":"2021-12-30T23:53:35.10714Z","iopub.status.idle":"2021-12-30T23:53:40.400798Z","shell.execute_reply.started":"2021-12-30T23:53:35.107102Z","shell.execute_reply":"2021-12-30T23:53:40.399907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_epochs now = 2\n\nclass ModelConfig:\n    EPOCHS = 1\n    BATCH_SIZE = 4\n    num_frames_per_second = 10\n    SEQUENCE_SIZE = 16\n    H = 256\n    W = 256\n    C = 1\n    TO_GRAY = True\n    overlapping = 0\n    rootdir = \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos\"\n    TRAIN_SAMPLE_NPZ_DIRECTORY = \"./npz_files\"\n    TEST_SAMPLE_NPZ_DIRECTORY = \"./npz_files\"\n    types = {\"Normal\":0, \"Abnormal\":1}\n    classes = {\"Explosion\":1, 'Burglary':2, 'Fighting':3, 'Assault':4, 'Arrest':5, 'Arson':6, 'Abuse':7}\n    extension = \"mp4\"\n    MODEL_WEIGHTS_DIRECTORY = \"./model_weights\"\n    COMBINE_MODEL_PATH = \"combined_model_weights.hdf5\"\n    GENERATOR_MODEL_PATH = \"generator_model_weights.hdf5\"\n    DISCRIMINATOR_MODEL_PATH = \"discriminator_model_weights.hdf5\"\n    CLASSIFIER_MODEL_PATH = \"classifier_model_weights.hdf5\"\n    AUTOENCODER_MODEL_PATH = \"autoencoder_model.hdf5\"","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.402269Z","iopub.execute_input":"2021-12-30T23:53:40.402755Z","iopub.status.idle":"2021-12-30T23:53:40.412672Z","shell.execute_reply.started":"2021-12-30T23:53:40.402711Z","shell.execute_reply":"2021-12-30T23:53:40.411825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)\nos.mkdir(ModelConfig.MODEL_WEIGHTS_DIRECTORY)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.413869Z","iopub.execute_input":"2021-12-30T23:53:40.414572Z","iopub.status.idle":"2021-12-30T23:53:40.427525Z","shell.execute_reply.started":"2021-12-30T23:53:40.414538Z","shell.execute_reply":"2021-12-30T23:53:40.426901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_video_times(cap):\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    duration = frame_count / fps\n\n    print('fps = ' + str(fps))\n    print('number of frames = ' + str(frame_count))\n    print('duration (S) = ' + str(duration))\n    minutes = int(duration / 60)\n    seconds = duration % 60\n    print('duration (M:S) = ' + str(minutes) + ':' + str(seconds))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.430407Z","iopub.execute_input":"2021-12-30T23:53:40.43124Z","iopub.status.idle":"2021-12-30T23:53:40.440029Z","shell.execute_reply.started":"2021-12-30T23:53:40.431193Z","shell.execute_reply":"2021-12-30T23:53:40.439342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SaveVideo2Npz(file_path, npz_directory, resize=(ModelConfig.H, ModelConfig.W), \n                  num_target_frames=ModelConfig.SEQUENCE_SIZE, overlapping=0):\n    cap = cv2.VideoCapture(file_path)\n    file_name = file_path.split('/')[-1]\n    file_name = file_name.split('.')[0]\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    #get_video_times(cap)\n    len_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    segments_path_list = []\n    if fps <= ModelConfig.num_frames_per_second:\n        step = fps\n    else:\n        step = int(fps / ModelConfig.num_frames_per_second)\n    try:\n        frames = []\n        num_sampled_video = 0\n        frame_index = 0\n        for i in range(0, len_frames):\n            _, frame = cap.read()\n            if i % step == 0:\n                frame = cv2.resize(frame, resize, interpolation=cv2.INTER_AREA)\n                if ModelConfig.TO_GRAY:\n                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                    frame = frame.reshape((ModelConfig.H, ModelConfig.W, ModelConfig.C))\n                else:\n                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n                frame = np.array(frame, dtype=np.float32)\n                frame /= 255.0\n                frames.append(frame)\n                frame_index += 1\n\n                if frame_index == num_target_frames:                    \n                    segments_path = os.path.join(npz_directory, file_name + \"_{}.npz\".format(num_sampled_video))\n                    num_sampled_video += 1\n                    np.savez(segments_path, np.array(frames))\n                    segments_path_list.append(segments_path)\n                    if overlapping == 0:\n                        frames.clear()\n                        frame_index = 0\n                    else:\n                        for _ in range(0, overlapping):\n                            frames.pop(0)\n                            frame_index -= 1\n    except Exception as e:\n        print(e)\n    finally:\n        cap.release()\n\n    return np.array(segments_path_list), fps","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.441381Z","iopub.execute_input":"2021-12-30T23:53:40.441912Z","iopub.status.idle":"2021-12-30T23:53:40.457387Z","shell.execute_reply.started":"2021-12-30T23:53:40.441867Z","shell.execute_reply":"2021-12-30T23:53:40.456676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# toooooooooooooooooooooooooo much memory\n\nskip_files = [\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary064_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Explosion/Explosion046_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest047_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Fighting/Fighting041_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arson/Arson019_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_940_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary095_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_935_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_924_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest049_x264.mp4\"\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.461695Z","iopub.execute_input":"2021-12-30T23:53:40.462276Z","iopub.status.idle":"2021-12-30T23:53:40.47287Z","shell.execute_reply.started":"2021-12-30T23:53:40.462237Z","shell.execute_reply":"2021-12-30T23:53:40.471906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# segments, _ = SaveVideo2Npz(\"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest049_x264.mp4\",\n#                             overlapping=ModelConfig.overlapping)\n\n# print(segments)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.474564Z","iopub.execute_input":"2021-12-30T23:53:40.474808Z","iopub.status.idle":"2021-12-30T23:53:40.487241Z","shell.execute_reply.started":"2021-12-30T23:53:40.474779Z","shell.execute_reply":"2021-12-30T23:53:40.486415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_npz_file(file_path):\n    dict_data = np.load(file_path)\n    data = dict_data['arr_0']\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.489427Z","iopub.execute_input":"2021-12-30T23:53:40.490027Z","iopub.status.idle":"2021-12-30T23:53:40.498998Z","shell.execute_reply.started":"2021-12-30T23:53:40.489982Z","shell.execute_reply":"2021-12-30T23:53:40.498065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frames = read_npz_file(segments[3])\n# plt.imshow(frames[1], cmap=\"gray\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.500573Z","iopub.execute_input":"2021-12-30T23:53:40.500805Z","iopub.status.idle":"2021-12-30T23:53:40.509282Z","shell.execute_reply.started":"2021-12-30T23:53:40.50078Z","shell.execute_reply":"2021-12-30T23:53:40.508651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_npz_directory(directorty_path):\n    for f in os.listdir(directorty_path):\n        os.remove(os.path.join(directorty_path, f))\n        \nclear_npz_directory(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)     ","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.510671Z","iopub.execute_input":"2021-12-30T23:53:40.510897Z","iopub.status.idle":"2021-12-30T23:53:40.522391Z","shell.execute_reply.started":"2021-12-30T23:53:40.510869Z","shell.execute_reply":"2021-12-30T23:53:40.521561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name_list = []\nfile_path_list = []\nfile_type_list = []\nfile_class_list = []\nfile_npy_path_list = []","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.523924Z","iopub.execute_input":"2021-12-30T23:53:40.524144Z","iopub.status.idle":"2021-12-30T23:53:40.533806Z","shell.execute_reply.started":"2021-12-30T23:53:40.524116Z","shell.execute_reply":"2021-12-30T23:53:40.532695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dataset_df():\n    global file_name_list \n    global file_path_list\n    global file_type_list \n    global file_class_list \n    global file_npy_path_list\n\n    file_name_list.clear()\n    file_path_list.clear()\n    file_type_list.clear()\n    file_class_list.clear()\n    file_npy_path_list.clear()\n\n\n    for root, subdirs, files in os.walk(ModelConfig.rootdir):\n        for filename in files:\n            if filename.split('.')[-1] != ModelConfig.extension:\n                continue\n\n            file_path = os.path.join(root, filename)\n            file_name = filename.split('.')[0]\n            \n            if file_path in skip_files:\n                continue\n            \n            file_name_list.append(file_name)\n            file_path_list.append(file_path)\n            file_class = file_path.split('/')[-2]\n            #print(file_class)\n            if file_class in ModelConfig.classes.keys():\n                file_type_list.append(ModelConfig.types[\"Abnormal\"])\n                file_class_list.append(ModelConfig.classes[file_class])\n            else:\n                file_type_list.append(ModelConfig.types[\"Normal\"])\n                file_class_list.append(ModelConfig.types[\"Normal\"])\n\n            #npy_path = Save2Npy(file_path, file_name, Config.save_npy_dir)\n            #file_npy_path_list.append(npy_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.53508Z","iopub.execute_input":"2021-12-30T23:53:40.535314Z","iopub.status.idle":"2021-12-30T23:53:40.547179Z","shell.execute_reply.started":"2021-12-30T23:53:40.535286Z","shell.execute_reply":"2021-12-30T23:53:40.546242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_dataset_df()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.548545Z","iopub.execute_input":"2021-12-30T23:53:40.549052Z","iopub.status.idle":"2021-12-30T23:53:40.643237Z","shell.execute_reply.started":"2021-12-30T23:53:40.54902Z","shell.execute_reply":"2021-12-30T23:53:40.642556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(file_path_list), len(file_name_list), len(file_type_list), len(file_class_list)#, len(file_npy_path_list)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.644647Z","iopub.execute_input":"2021-12-30T23:53:40.6451Z","iopub.status.idle":"2021-12-30T23:53:40.65255Z","shell.execute_reply.started":"2021-12-30T23:53:40.645059Z","shell.execute_reply":"2021-12-30T23:53:40.651561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list, file_npy_path_list)),\n#                          columns =['file_name', 'file_path', 'file_type', 'file_class', 'npy_file_path'])\n\ndataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list)),\n                          columns =['file_name', 'file_path', 'file_type', 'file_class'])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.654199Z","iopub.execute_input":"2021-12-30T23:53:40.654575Z","iopub.status.idle":"2021-12-30T23:53:40.668778Z","shell.execute_reply.started":"2021-12-30T23:53:40.654547Z","shell.execute_reply":"2021-12-30T23:53:40.668123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.669929Z","iopub.execute_input":"2021-12-30T23:53:40.670472Z","iopub.status.idle":"2021-12-30T23:53:40.693098Z","shell.execute_reply.started":"2021-12-30T23:53:40.670439Z","shell.execute_reply":"2021-12-30T23:53:40.692534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\n\n\nclass CustomDataGen(tf.keras.utils.Sequence):\n    def __init__(self, dataset_df, X_col, y_col, directory, npz_directory, shuffle=True, data_augmentation=True):\n        self.batch_size = 1\n        self.dataset_df = dataset_df\n        self.X_col = X_col\n        self.y_col = y_col\n        self.directory = directory\n        self.npz_directory = npz_directory\n        self.shuffle = shuffle\n        self.data_aug = data_augmentation\n        self.classes = np.unique(self.dataset_df[self.y_col])\n        self.num_classes =  len(self.classes)\n        self.X_path, self.Y_dict = self.search_data() \n        self.print_stats()\n        return None\n        \n    def search_data(self):\n        X_path = []\n        Y_dict = {}\n        one_hots = to_categorical(self.dataset_df[self.y_col], self.num_classes)\n        for index in range(len(self.dataset_df)):\n            X_path.append(self.dataset_df.at[index, self.X_col])\n            Y_dict[X_path[-1]] = one_hots[index]\n        return X_path, Y_dict\n    \n    def print_stats(self):\n        self.n_files = len(self.X_path)\n        self.indexes = np.arange(len(self.X_path))\n        np.random.shuffle(self.indexes)\n        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.num_classes))\n    \n    def __len__(self):\n        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n        return int(steps_per_epoch)\n\n    def __getitem__(self, index):\n        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_path = [self.X_path[k] for k in batch_indexs]\n        batch_x, batch_y = self.data_generation(batch_path)               \n        return batch_x, batch_y\n    \n    def get_mini_batch(self, index):\n        return self.__getitem__(index)\n\n    def on_epoch_end(self):\n        # shuffle the data at each end of epoch\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def data_generation(self, batch_path):\n        batch_x = [self.load_data(x) for x in batch_path]\n        batch_y = [self.Y_dict[x] for x in batch_path]\n\n        batch_x = np.array(batch_x)\n        batch_y = np.array(batch_y)\n        return batch_x, batch_y\n    \n    def load_data(self, path):\n        #print(path)\n        segments, _  = SaveVideo2Npz(path, self.npz_directory, \n                                     resize=(ModelConfig.H, ModelConfig.W), \n                                     num_target_frames=ModelConfig.SEQUENCE_SIZE,\n                                     overlapping=ModelConfig.overlapping)\n        return segments","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:40.694225Z","iopub.execute_input":"2021-12-30T23:53:40.694591Z","iopub.status.idle":"2021-12-30T23:53:41.83739Z","shell.execute_reply.started":"2021-12-30T23:53:40.694563Z","shell.execute_reply":"2021-12-30T23:53:41.83633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = CustomDataGen(dataset_df,\n                           X_col=\"file_path\",\n                           y_col=\"file_class\",\n                           directory = ModelConfig.rootdir, \n                           npz_directory = ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY,\n                           shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:41.839281Z","iopub.execute_input":"2021-12-30T23:53:41.83961Z","iopub.status.idle":"2021-12-30T23:53:41.86109Z","shell.execute_reply.started":"2021-12-30T23:53:41.839569Z","shell.execute_reply":"2021-12-30T23:53:41.859977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen.get_mini_batch(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:41.862629Z","iopub.execute_input":"2021-12-30T23:53:41.863327Z","iopub.status.idle":"2021-12-30T23:53:43.897056Z","shell.execute_reply.started":"2021-12-30T23:53:41.863289Z","shell.execute_reply":"2021-12-30T23:53:43.896183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \n\nn = random.randint(0, len(dataset_df))\nrandomlist = random.sample(range(0, len(dataset_df)), len(dataset_df)) \nval_size = 0.1\nval_size = int(len(dataset_df) * val_size)\nval_size = randomlist[:val_size]\nvalidation_df = dataset_df.iloc[val_size].reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:43.898149Z","iopub.execute_input":"2021-12-30T23:53:43.898352Z","iopub.status.idle":"2021-12-30T23:53:43.909401Z","shell.execute_reply.started":"2021-12-30T23:53:43.898327Z","shell.execute_reply":"2021-12-30T23:53:43.908563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation_df","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:43.910902Z","iopub.execute_input":"2021-12-30T23:53:43.911127Z","iopub.status.idle":"2021-12-30T23:53:43.918321Z","shell.execute_reply.started":"2021-12-30T23:53:43.911099Z","shell.execute_reply":"2021-12-30T23:53:43.917474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_gen = CustomDataGen(validation_df,\n                               X_col=\"file_path\",\n                               y_col=\"file_class\",\n                               directory = ModelConfig.rootdir,\n                               npz_directory=ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY,\n                               shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T23:53:43.920156Z","iopub.execute_input":"2021-12-30T23:53:43.920666Z","iopub.status.idle":"2021-12-30T23:53:43.930964Z","shell.execute_reply.started":"2021-12-30T23:53:43.920634Z","shell.execute_reply":"2021-12-30T23:53:43.929984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import (Input, Conv3D, Conv3DTranspose,\n                                     ConvLSTM2D)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\n\n\ndef encoder(X_input):\n    # encoder    \n    X = Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='same',activation='tanh')(X_input)\n\n    X = Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='same',activation='tanh')(X)\n\n    X = ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True)(X)\n\n    bottleneck = ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True)(X)\n    \n    return bottleneck\n\n    \ndef decoder(bottleneck):\n    # decoder\n    X = ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5, name=\"decoder_layer\")(bottleneck)\n\n    X = Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='same',activation='tanh')(X)\n\n    X = Conv3DTranspose(filters=ModelConfig.C,kernel_size=(11,11,1),strides=(4,4,1),padding='same',activation='sigmoid')(X)\n\n    return X\n\ndef AutoEncoderModel(X_input):\n    autoencoder = Model(X_input, decoder(encoder(X_input)), name='AutoEncoderModel')\n    return autoencoder\n\n\ndef custom_loss(new, original):\n    reconstruct_loss = K.mean(K.square(new-original))\n    return reconstruct_loss\n\nX_input = Input(shape=(ModelConfig.H,ModelConfig.W,ModelConfig.SEQUENCE_SIZE,ModelConfig.C))\nautoEncoderModel = AutoEncoderModel(X_input)\nopt = Adam(lr=0.001)\nautoEncoderModel.compile(loss=custom_loss, optimizer=opt, metrics=['accuracy'])\nprint(autoEncoderModel.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:49:25.995783Z","iopub.execute_input":"2021-12-30T20:49:25.996028Z","iopub.status.idle":"2021-12-30T20:49:26.483923Z","shell.execute_reply.started":"2021-12-30T20:49:25.996001Z","shell.execute_reply":"2021-12-30T20:49:26.482453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.layers import Conv3D,ConvLSTM2D, Flatten, Dense, Input,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\n\ndef create_discriminator_model():\n\n    model= tf.keras.Sequential()\n    model.add(Input((ModelConfig.H,ModelConfig.W,ModelConfig.SEQUENCE_SIZE,ModelConfig.C)))\n\n    model.add(Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='same',activation='tanh'))\n\n    model.add(Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='same',activation='tanh'))\n\n    model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True))\n\n    model.add(ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True))\n\n    model.add(Conv3D(filters=16,kernel_size=(5,5,1),strides=(2,2,1),padding='same',activation='tanh'))\n\n    model.add(Conv3D(filters=8,kernel_size=(7,7,1),strides=(3,3,1),padding='same',activation='tanh'))\n\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model\n\n# def DiscriminatorModel(X_input):\n#     discriminator = Model(X_input, create_discriminator_model(X_input), name='Discriminator')\n#     return discriminator\n\n#X_input = Input(shape=(ModelConfig.H,ModelConfig.W,ModelConfig.SEQUENCE_SIZE,ModelConfig.C))\ndiscriminator = create_discriminator_model()\nopt = Adam(lr=0.001)\nloss = BinaryCrossentropy()\ndiscriminator.compile(loss=loss,\n                      optimizer=opt,\n                      metrics=['accuracy'])\nprint(discriminator.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:49:27.280812Z","iopub.execute_input":"2021-12-30T20:49:27.281054Z","iopub.status.idle":"2021-12-30T20:49:27.546212Z","shell.execute_reply.started":"2021-12-30T20:49:27.281026Z","shell.execute_reply":"2021-12-30T20:49:27.545493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_result(autoencoder_model, gan_model, batch_num, X, epoch, img_seq_num=-1 ,image_idx=-1):\n    mini_batch_size = X.shape[0]\n    valid_y = np.array([1] * mini_batch_size)\n    seq = autoencoder_model.predict(X)\n    y_hat = gan_model.predict(X)\n    \n    X = np.transpose(X, (0, 3, 1, 2, 4))\n    seq = np.transpose(seq, (0, 3, 1, 2, 4))\n    \n    result = []\n    result.append(X[img_seq_num][image_idx])\n    result.append(seq[img_seq_num][image_idx])\n    result = np.array(result)\n    print(\"Epoch: {}, Batch_number: {}\".format(epoch, batch_num))\n    print(\"y_hat:{}\".format(round(y_hat[img_seq_num][0])))\n    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,20))\n    for i, ax in enumerate(axs.flatten()):\n        plt.sca(ax)\n        if ModelConfig.TO_GRAY:\n            plt.imshow(result[i].reshape(ModelConfig.H, ModelConfig.W), cmap=\"gray\")\n        else:\n            plt.imshow(result[i])\n        if i % 2 == 0:\n            plt.title('Original Image: {}'.format(i+1))\n        else:\n            plt.title('Reconstructed Image: {}'.format(i+1))\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:52:26.1879Z","iopub.execute_input":"2021-12-30T20:52:26.188605Z","iopub.status.idle":"2021-12-30T20:52:26.198267Z","shell.execute_reply.started":"2021-12-30T20:52:26.188563Z","shell.execute_reply":"2021-12-30T20:52:26.197392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom tensorflow.keras.utils import Progbar\n\nclass GAN():\n    def __init__(self):        \n        self.image_shape=(ModelConfig.H, ModelConfig.W,ModelConfig.SEQUENCE_SIZE, ModelConfig.C)\n\n        learning_rate=0.0002\n        beta_1=0.5    \n\n        opt1=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6)\n        opt2=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6)\n        opt3=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6)\n        \n        #Build and compile the discriminator\n        self.discriminator=create_discriminator_model()\n        self.discriminator.compile(loss=BinaryCrossentropy(),optimizer=opt1,metrics=['accuracy'])\n        \n        #Build and compile the generator\n        X_input = Input(shape=(self.image_shape))\n        self.generator = AutoEncoderModel(X_input)\n        self.generator.compile(loss='mse',optimizer=opt2)\n        \n        #the generator takes a video as input and generates a modified video\n        z = Input(shape=(self.image_shape))\n        img = self.generator(z)\n        validity = self.discriminator(img)\n        self.combined = Model(z, validity)\n        self.combined.compile(loss=BinaryCrossentropy(), optimizer=opt3, metrics=['accuracy'])\n\n    def re_init_combine(self, generator, discriminator):\n        self.generator = generator\n        self.discriminator = discriminator\n        z = Input(shape=(self.image_shape))\n        img = self.generator(z)\n        validity = self.discriminator(img)\n        self.combined = Model(z, validity)\n        opt3=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6)\n        self.combined.compile(loss=BinaryCrossentropy(), optimizer=opt3, metrics=['accuracy'])\n\n    def train_gan(self, train_gen):\n        for epoch in range(ModelConfig.EPOCHS):\n            d_loss_sum=tf.zeros(2)\n            g_loss_sum=tf.zeros(2)\n            reconstruct_loss_sum=0\n            no_of_minibatches=0\n            progress_bar = Progbar(target=len(train_gen))\n            print(\"Epoch : \", epoch+1)\n            for i in range(len(train_gen)):\n                sample_reconstruct_loss=0\n                sample_d_loss=0\n                sample_g_loss=0\n                X_sample, _ = train_gen.get_mini_batch(i)\n                X_sample = X_sample[0]\n                X_sample_size = X_sample.shape[0]                \n                minibatch = None\n                j = 0\n                num_segments = 0\n                while j < X_sample_size:\n                    minibatch = []\n                    mini_batch_size = min(ModelConfig.BATCH_SIZE, X_sample_size-j)\n                    seg_indxes = list(range(j, j+mini_batch_size))\n                    minibatch = np.array([read_npz_file(X_sample[index]) for index in seg_indxes])\n                    j+=mini_batch_size\n\n                    minibatch = np.transpose(minibatch, (0, 2, 3, 1, 4))\n                    \n                    gen_vids=self.generator.predict(minibatch)\n\n                    #might have to combine these to improve batch norm\n                    self.discriminator.trainable=True\n                    d_loss_real, _ = self.discriminator.train_on_batch(minibatch, tf.ones((mini_batch_size,1)))\n                    d_loss_fake, _ = self.discriminator.train_on_batch(gen_vids, tf.zeros((mini_batch_size,1)))\n                    d_loss=0.5*tf.math.add(d_loss_real,d_loss_fake)\n                    # ---------------------\n                    #  Train Generator\n                    # ---------------------\n                    # The generator wants the discriminator to label the generated samples as valid (ones)\n                    valid_y = tf.ones((mini_batch_size,1))\n                    # Train the generator\n                    self.discriminator.trainable=False\n                    g_loss, _ = self.combined.train_on_batch(minibatch,valid_y)\n\n                    reconstruct_loss=self.generator.train_on_batch(minibatch,minibatch)\n\n                    sample_d_loss+=d_loss \n                    sample_g_loss+=g_loss \n                    sample_reconstruct_loss+=reconstruct_loss      \n                    num_segments += 1\n                clear_npz_directory(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)\n                \n                if i % 10 == 0:\n                    visualize_result(self.generator, self.combined, i, minibatch, epoch+1, img_seq_num=-1 ,image_idx=-1)\n                    self.generator.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.GENERATOR_MODEL_PATH))\n                    self.discriminator.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.DISCRIMINATOR_MODEL_PATH))\n                    self.combined.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.COMBINE_MODEL_PATH))\n                \n                g_loss_sum+=(sample_d_loss/num_segments)\n                d_loss_sum+=(sample_g_loss/num_segments)\n                reconstruct_loss_sum+=(sample_reconstruct_loss/num_segments)\n                progress_bar.update(i+1, \n                                    values=[('d_loss', (sample_d_loss/num_segments)),\n                                            ('g_loss', (sample_g_loss/num_segments)),\n                                            ('rec_loss', (sample_reconstruct_loss/num_segments))])\n                print()\n\n            g_loss=g_loss_sum/len(train_gen)\n            d_loss=d_loss_sum/len(train_gen)\n            reconstruct_loss=reconstruct_loss_sum/len(train_gen)\n\n            print(\"(^|^)  ('|')\")\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, accuracy %.2f%% from which %f is combined loss and %f is reconstruction loss]\" % \n                  (epoch+1, \n                   d_loss[0], \n                   100*d_loss[1], \n                   g_loss[0]+reconstruct_loss,\n                   g_loss[1]*100,\n                   g_loss[0],\n                   reconstruct_loss))\n            \n            self.generator.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.GENERATOR_MODEL_PATH))\n            self.discriminator.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.DISCRIMINATOR_MODEL_PATH))\n            self.combined.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.COMBINE_MODEL_PATH))\n            train_gen.on_epoch_end()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:57:01.918776Z","iopub.execute_input":"2021-12-30T20:57:01.919318Z","iopub.status.idle":"2021-12-30T20:57:01.951821Z","shell.execute_reply.started":"2021-12-30T20:57:01.91928Z","shell.execute_reply":"2021-12-30T20:57:01.951205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan = GAN()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:57:02.158692Z","iopub.execute_input":"2021-12-30T20:57:02.158889Z","iopub.status.idle":"2021-12-30T20:57:04.444553Z","shell.execute_reply.started":"2021-12-30T20:57:02.158866Z","shell.execute_reply":"2021-12-30T20:57:04.44381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gan.generator.summary())\nprint(gan.discriminator.summary())\nprint(gan.combined.summary())\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:57:04.446142Z","iopub.execute_input":"2021-12-30T20:57:04.446369Z","iopub.status.idle":"2021-12-30T20:57:04.467546Z","shell.execute_reply.started":"2021-12-30T20:57:04.446333Z","shell.execute_reply":"2021-12-30T20:57:04.466914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gan.generator.load_weights(\"./UCSDGANWeights/UCF_generator_model_weights.hdf5\")\n# gan.discriminator.load_weights(\"./UCSDGANWeights/UCF_discriminator_model_weights.hdf5\")\n# #gan.combined.load_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.COMBINE_MODEL_PATH))\n# gan.re_init_combine(gan.generator, gan.discriminator)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:57:04.469041Z","iopub.execute_input":"2021-12-30T20:57:04.469294Z","iopub.status.idle":"2021-12-30T20:57:04.473022Z","shell.execute_reply.started":"2021-12-30T20:57:04.469251Z","shell.execute_reply":"2021-12-30T20:57:04.472182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gan.generator.load_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.GENERATOR_MODEL_PATH))\n# gan.discriminator.load_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.DISCRIMINATOR_MODEL_PATH))\n# #gan.combined.load_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.COMBINE_MODEL_PATH))\n# gan.re_init_combine(gan.generator, gan.discriminator)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:57:04.94476Z","iopub.execute_input":"2021-12-30T20:57:04.94508Z","iopub.status.idle":"2021-12-30T20:57:04.949582Z","shell.execute_reply.started":"2021-12-30T20:57:04.945043Z","shell.execute_reply":"2021-12-30T20:57:04.948649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n\nwith tf.device(device_name):\n    gan = GAN()\n    gan.train_gan(train_gen)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T20:57:05.617364Z","iopub.execute_input":"2021-12-30T20:57:05.617902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}