{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nnp.random.seed(333)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-01T12:43:56.429835Z","iopub.execute_input":"2022-01-01T12:43:56.430135Z","iopub.status.idle":"2022-01-01T12:43:56.436314Z","shell.execute_reply.started":"2022-01-01T12:43:56.430104Z","shell.execute_reply":"2022-01-01T12:43:56.43515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:43:56.681572Z","iopub.execute_input":"2022-01-01T12:43:56.681959Z","iopub.status.idle":"2022-01-01T12:43:56.687085Z","shell.execute_reply.started":"2022-01-01T12:43:56.681928Z","shell.execute_reply":"2022-01-01T12:43:56.685618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gdrive_folder_link=\"https://drive.google.com/drive/folders/1RpD6itBuWYCdFeTjVilt9CKPgDvqoitq?usp=sharing\"","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:43:57.097753Z","iopub.execute_input":"2022-01-01T12:43:57.098006Z","iopub.status.idle":"2022-01-01T12:43:57.102119Z","shell.execute_reply.started":"2022-01-01T12:43:57.097977Z","shell.execute_reply":"2022-01-01T12:43:57.101012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gdown\n# gdown.download_folder(gdrive_folder_link, quiet=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:43:57.357557Z","iopub.execute_input":"2022-01-01T12:43:57.357924Z","iopub.status.idle":"2022-01-01T12:43:57.362797Z","shell.execute_reply.started":"2022-01-01T12:43:57.357893Z","shell.execute_reply":"2022-01-01T12:43:57.361449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport time\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:43:57.864387Z","iopub.execute_input":"2022-01-01T12:43:57.865021Z","iopub.status.idle":"2022-01-01T12:43:58.107437Z","shell.execute_reply.started":"2022-01-01T12:43:57.864983Z","shell.execute_reply":"2022-01-01T12:43:58.106303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:43:58.27436Z","iopub.execute_input":"2022-01-01T12:43:58.27519Z","iopub.status.idle":"2022-01-01T12:44:05.707832Z","shell.execute_reply.started":"2022-01-01T12:43:58.275157Z","shell.execute_reply":"2022-01-01T12:44:05.706187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_epochs now = 2\n\nclass ModelConfig:\n    EPOCHS = 10\n    BATCH_SIZE = 4\n    num_frames_per_second = 10\n    SEQUENCE_SIZE = 16\n    H = 256\n    W = 256\n    C = 1\n    TO_GRAY = True\n    overlapping = 0\n    rootdir = \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos\"\n    TRAIN_SAMPLE_NPZ_DIRECTORY = \"./npz_files\"\n    TEST_SAMPLE_NPZ_DIRECTORY = \"./npz_files\"\n    types = {\"Normal\":0, \"Abnormal\":1}\n    classes = {\"Explosion\":1, 'Burglary':2, 'Fighting':3, 'Assault':4, 'Arrest':5, 'Arson':6, 'Abuse':7}\n    extension = \"mp4\"\n    MODEL_WEIGHTS_DIRECTORY = \"./model_weights\"\n    COMBINE_MODEL_PATH = \"combined_model_weights.hdf5\"\n    GENERATOR_MODEL_PATH = \"generator_model_weights.hdf5\"\n    DISCRIMINATOR_MODEL_PATH = \"discriminator_model_weights.hdf5\"\n    CLASSIFIER_MODEL_PATH = \"classifier_model_weights.hdf5\"\n    AUTOENCODER_MODEL_PATH = \"autoencoder_model.hdf5\"","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.71016Z","iopub.execute_input":"2022-01-01T12:44:05.712179Z","iopub.status.idle":"2022-01-01T12:44:05.721916Z","shell.execute_reply.started":"2022-01-01T12:44:05.712131Z","shell.execute_reply":"2022-01-01T12:44:05.720689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)\nos.mkdir(ModelConfig.MODEL_WEIGHTS_DIRECTORY)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.724645Z","iopub.execute_input":"2022-01-01T12:44:05.724981Z","iopub.status.idle":"2022-01-01T12:44:05.735589Z","shell.execute_reply.started":"2022-01-01T12:44:05.724938Z","shell.execute_reply":"2022-01-01T12:44:05.734495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_video_times(cap):\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    duration = frame_count / fps\n\n    print('fps = ' + str(fps))\n    print('number of frames = ' + str(frame_count))\n    print('duration (S) = ' + str(duration))\n    minutes = int(duration / 60)\n    seconds = duration % 60\n    print('duration (M:S) = ' + str(minutes) + ':' + str(seconds))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.738784Z","iopub.execute_input":"2022-01-01T12:44:05.739119Z","iopub.status.idle":"2022-01-01T12:44:05.747792Z","shell.execute_reply.started":"2022-01-01T12:44:05.739074Z","shell.execute_reply":"2022-01-01T12:44:05.746708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image_black_background(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n    hh, ww = thresh.shape\n    thresh[hh:hh, 0:ww] = 0\n    white = np.where(thresh == 255)\n    \n    if len(white[0]) <= 1 or len(white[1]) <= 1:\n        return None\n    \n    xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n    crop = img[ymin:ymax, xmin:xmax]\n    \n    if (crop.shape[0] < img.shape[0]/2) and (crop.shape[1] < img.shape[1]/2):\n        return None\n    \n    return crop","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.749698Z","iopub.execute_input":"2022-01-01T12:44:05.750815Z","iopub.status.idle":"2022-01-01T12:44:05.763057Z","shell.execute_reply.started":"2022-01-01T12:44:05.750769Z","shell.execute_reply":"2022-01-01T12:44:05.761882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SaveVideo2Npz(file_path, npz_directory, resize=(ModelConfig.H, ModelConfig.W), \n                  num_target_frames=ModelConfig.SEQUENCE_SIZE, overlapping=0):\n    cap = cv2.VideoCapture(file_path)\n    file_name = file_path.split('/')[-1]\n    file_name = file_name.split('.')[0]\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    #get_video_times(cap)\n    len_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    segments_path_list = []\n    if fps <= ModelConfig.num_frames_per_second:\n        step = fps\n    else:\n        step = int(fps / ModelConfig.num_frames_per_second)\n    try:\n        frames = []\n        num_sampled_video = 0\n        frame_index = 0\n        for i in range(0, len_frames):\n            _, frame = cap.read()\n#             frame = crop_image_black_background(frame)\n#             if frame is None:\n#                 continue\n                \n            if i % step == 0:\n                frame = cv2.resize(frame, resize, interpolation=cv2.INTER_AREA)                \n                if ModelConfig.TO_GRAY:\n                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                    frame = frame.reshape((ModelConfig.H, ModelConfig.W, ModelConfig.C))\n                else:\n                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n                frame = np.array(frame, dtype=np.float32)\n                frame /= 255.0\n                frames.append(frame)\n                frame_index += 1\n\n                if frame_index == num_target_frames:                    \n                    segments_path = os.path.join(npz_directory, file_name + \"_{}.npz\".format(num_sampled_video))\n                    num_sampled_video += 1\n                    np.savez(segments_path, np.array(frames))\n                    segments_path_list.append(segments_path)\n                    if overlapping == 0:\n                        frames.clear()\n                        frame_index = 0\n                    else:\n                        for _ in range(0, overlapping):\n                            frames.pop(0)\n                            frame_index -= 1\n    except Exception as e:\n        print(e)\n    finally:\n        cap.release()\n\n    return np.array(segments_path_list), fps","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.780786Z","iopub.execute_input":"2022-01-01T12:44:05.781296Z","iopub.status.idle":"2022-01-01T12:44:05.800401Z","shell.execute_reply.started":"2022-01-01T12:44:05.781253Z","shell.execute_reply":"2022-01-01T12:44:05.799405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# toooooooooooooooooooooooooo much memory\n\nskip_files = [\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary064_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Explosion/Explosion046_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest047_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Fighting/Fighting041_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arson/Arson019_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_940_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary095_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_935_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_924_x264.mp4\",\n    \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest049_x264.mp4\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.801504Z","iopub.execute_input":"2022-01-01T12:44:05.801848Z","iopub.status.idle":"2022-01-01T12:44:05.815748Z","shell.execute_reply.started":"2022-01-01T12:44:05.801799Z","shell.execute_reply":"2022-01-01T12:44:05.814568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# segments, _ = SaveVideo2Npz(\"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest049_x264.mp4\",\n#                             overlapping=ModelConfig.overlapping)\n\n# print(segments)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.817369Z","iopub.execute_input":"2022-01-01T12:44:05.818073Z","iopub.status.idle":"2022-01-01T12:44:05.830208Z","shell.execute_reply.started":"2022-01-01T12:44:05.818027Z","shell.execute_reply":"2022-01-01T12:44:05.829232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_npz_file(file_path):\n    dict_data = np.load(file_path)\n    data = dict_data['arr_0']\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.835313Z","iopub.execute_input":"2022-01-01T12:44:05.835593Z","iopub.status.idle":"2022-01-01T12:44:05.842763Z","shell.execute_reply.started":"2022-01-01T12:44:05.835546Z","shell.execute_reply":"2022-01-01T12:44:05.841752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frames = read_npz_file(segments[3])\n# plt.imshow(frames[1], cmap=\"gray\")\n","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.844809Z","iopub.execute_input":"2022-01-01T12:44:05.845155Z","iopub.status.idle":"2022-01-01T12:44:05.852588Z","shell.execute_reply.started":"2022-01-01T12:44:05.845111Z","shell.execute_reply":"2022-01-01T12:44:05.851672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_npz_directory(directorty_path):\n    for f in os.listdir(directorty_path):\n        os.remove(os.path.join(directorty_path, f))\n        \nclear_npz_directory(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)     ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.856161Z","iopub.execute_input":"2022-01-01T12:44:05.856472Z","iopub.status.idle":"2022-01-01T12:44:05.865212Z","shell.execute_reply.started":"2022-01-01T12:44:05.856428Z","shell.execute_reply":"2022-01-01T12:44:05.864163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name_list = []\nfile_path_list = []\nfile_type_list = []\nfile_class_list = []\nfile_npy_path_list = []","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.867033Z","iopub.execute_input":"2022-01-01T12:44:05.868107Z","iopub.status.idle":"2022-01-01T12:44:05.875917Z","shell.execute_reply.started":"2022-01-01T12:44:05.868045Z","shell.execute_reply":"2022-01-01T12:44:05.874838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dataset_df():\n    global file_name_list \n    global file_path_list\n    global file_type_list \n    global file_class_list \n    global file_npy_path_list\n\n    file_name_list.clear()\n    file_path_list.clear()\n    file_type_list.clear()\n    file_class_list.clear()\n    file_npy_path_list.clear()\n\n\n    for root, subdirs, files in os.walk(ModelConfig.rootdir):\n        for filename in files:\n            if filename.split('.')[-1] != ModelConfig.extension:\n                continue\n\n            file_path = os.path.join(root, filename)\n            file_name = filename.split('.')[0]\n            \n            if file_path in skip_files:\n                continue\n            \n            file_name_list.append(file_name)\n            file_path_list.append(file_path)\n            file_class = file_path.split('/')[-2]\n            #print(file_class)\n            if file_class in ModelConfig.classes.keys():\n                file_type_list.append(ModelConfig.types[\"Abnormal\"])\n                file_class_list.append(ModelConfig.classes[file_class])\n            else:\n                file_type_list.append(ModelConfig.types[\"Normal\"])\n                file_class_list.append(ModelConfig.types[\"Normal\"])\n\n            #npy_path = Save2Npy(file_path, file_name, Config.save_npy_dir)\n            #file_npy_path_list.append(npy_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.878068Z","iopub.execute_input":"2022-01-01T12:44:05.878422Z","iopub.status.idle":"2022-01-01T12:44:05.892534Z","shell.execute_reply.started":"2022-01-01T12:44:05.878349Z","shell.execute_reply":"2022-01-01T12:44:05.891407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_dataset_df()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:05.894408Z","iopub.execute_input":"2022-01-01T12:44:05.895043Z","iopub.status.idle":"2022-01-01T12:44:06.131352Z","shell.execute_reply.started":"2022-01-01T12:44:05.894995Z","shell.execute_reply":"2022-01-01T12:44:06.130349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(file_path_list), len(file_name_list), len(file_type_list), len(file_class_list)#, len(file_npy_path_list)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:06.134677Z","iopub.execute_input":"2022-01-01T12:44:06.135003Z","iopub.status.idle":"2022-01-01T12:44:06.145734Z","shell.execute_reply.started":"2022-01-01T12:44:06.134957Z","shell.execute_reply":"2022-01-01T12:44:06.144698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list, file_npy_path_list)),\n#                          columns =['file_name', 'file_path', 'file_type', 'file_class', 'npy_file_path'])\n\ndataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list)),\n                          columns =['file_name', 'file_path', 'file_type', 'file_class'])","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:06.165193Z","iopub.execute_input":"2022-01-01T12:44:06.165864Z","iopub.status.idle":"2022-01-01T12:44:06.176921Z","shell.execute_reply.started":"2022-01-01T12:44:06.165828Z","shell.execute_reply":"2022-01-01T12:44:06.175841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:06.354585Z","iopub.execute_input":"2022-01-01T12:44:06.355368Z","iopub.status.idle":"2022-01-01T12:44:06.379545Z","shell.execute_reply.started":"2022-01-01T12:44:06.355317Z","shell.execute_reply":"2022-01-01T12:44:06.378519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\n\n\nclass CustomDataGen(tf.keras.utils.Sequence):\n    def __init__(self, dataset_df, X_col, y_col, directory, npz_directory, shuffle=True, data_augmentation=True):\n        self.batch_size = 1\n        self.dataset_df = dataset_df\n        self.X_col = X_col\n        self.y_col = y_col\n        self.directory = directory\n        self.npz_directory = npz_directory\n        self.shuffle = shuffle\n        self.data_aug = data_augmentation\n        self.classes = np.unique(self.dataset_df[self.y_col])\n        self.num_classes =  len(self.classes)\n        self.X_path, self.Y_dict = self.search_data() \n        self.print_stats()\n        return None\n        \n    def search_data(self):\n        X_path = []\n        Y_dict = {}\n        one_hots = to_categorical(self.dataset_df[self.y_col], self.num_classes)\n        for index in range(len(self.dataset_df)):\n            X_path.append(self.dataset_df.at[index, self.X_col])\n            Y_dict[X_path[-1]] = one_hots[index]\n        return X_path, Y_dict\n    \n    def print_stats(self):\n        self.n_files = len(self.X_path)\n        self.indexes = np.arange(len(self.X_path))\n        np.random.shuffle(self.indexes)\n        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.num_classes))\n    \n    def __len__(self):\n        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n        return int(steps_per_epoch)\n\n    def __getitem__(self, index):\n        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_path = [self.X_path[k] for k in batch_indexs]\n        batch_x, batch_y = self.data_generation(batch_path)               \n        return batch_x, batch_y\n    \n    def get_mini_batch(self, index):\n        return self.__getitem__(index)\n\n    def on_epoch_end(self):\n        # shuffle the data at each end of epoch\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def data_generation(self, batch_path):\n        batch_x = [self.load_data(x) for x in batch_path]\n        batch_y = [self.Y_dict[x] for x in batch_path]\n\n        batch_x = np.array(batch_x)\n        batch_y = np.array(batch_y)\n        return batch_x, batch_y\n    \n    def load_data(self, path):\n        #print(path)\n        segments, _  = SaveVideo2Npz(path, self.npz_directory, \n                                     resize=(ModelConfig.H, ModelConfig.W), \n                                     num_target_frames=ModelConfig.SEQUENCE_SIZE,\n                                     overlapping=ModelConfig.overlapping)\n        return segments","metadata":{"execution":{"iopub.status.busy":"2022-01-01T12:44:06.941413Z","iopub.execute_input":"2022-01-01T12:44:06.941727Z","iopub.status.idle":"2022-01-01T12:44:07.956566Z","shell.execute_reply.started":"2022-01-01T12:44:06.941695Z","shell.execute_reply":"2022-01-01T12:44:07.955513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = CustomDataGen(dataset_df,\n                           X_col=\"file_path\",\n                           y_col=\"file_class\",\n                           directory = ModelConfig.rootdir, \n                           npz_directory = ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY,\n                           shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:13.497507Z","iopub.execute_input":"2022-01-01T13:38:13.497919Z","iopub.status.idle":"2022-01-01T13:38:13.510276Z","shell.execute_reply.started":"2022-01-01T13:38:13.497866Z","shell.execute_reply":"2022-01-01T13:38:13.50918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen.get_mini_batch(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:14.321301Z","iopub.execute_input":"2022-01-01T13:38:14.322035Z","iopub.status.idle":"2022-01-01T13:38:16.712139Z","shell.execute_reply.started":"2022-01-01T13:38:14.321971Z","shell.execute_reply":"2022-01-01T13:38:16.711191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \n\nn = random.randint(0, len(dataset_df))\nrandomlist = random.sample(range(0, len(dataset_df)), len(dataset_df)) \nval_size = 0.1\nval_size = int(len(dataset_df) * val_size)\nval_size = randomlist[:val_size]\nvalidation_df = dataset_df.iloc[val_size].reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:17.491888Z","iopub.execute_input":"2022-01-01T13:38:17.49272Z","iopub.status.idle":"2022-01-01T13:38:17.502779Z","shell.execute_reply.started":"2022-01-01T13:38:17.492678Z","shell.execute_reply":"2022-01-01T13:38:17.501679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation_df","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:18.879013Z","iopub.execute_input":"2022-01-01T13:38:18.879317Z","iopub.status.idle":"2022-01-01T13:38:18.885438Z","shell.execute_reply.started":"2022-01-01T13:38:18.879285Z","shell.execute_reply":"2022-01-01T13:38:18.883462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_gen = CustomDataGen(validation_df,\n                               X_col=\"file_path\",\n                               y_col=\"file_class\",\n                               directory = ModelConfig.rootdir,\n                               npz_directory=ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY,\n                               shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:19.430781Z","iopub.execute_input":"2022-01-01T13:38:19.431593Z","iopub.status.idle":"2022-01-01T13:38:19.439352Z","shell.execute_reply.started":"2022-01-01T13:38:19.431526Z","shell.execute_reply":"2022-01-01T13:38:19.438056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import (Input, Conv3D, Conv3DTranspose,\n                                     ConvLSTM2D)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\n\n\ndef encoder(X_input):\n    # encoder    \n    X = Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='same',activation='tanh')(X_input)\n\n    X = Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='same',activation='tanh')(X)\n\n    X = ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True)(X)\n\n    bottleneck = ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True)(X)\n    \n    return bottleneck\n\n    \ndef decoder(bottleneck):\n    # decoder\n    X = ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5, name=\"decoder_layer\")(bottleneck)\n\n    X = Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='same',activation='tanh')(X)\n\n    X = Conv3DTranspose(filters=ModelConfig.C,kernel_size=(11,11,1),strides=(4,4,1),padding='same',activation='sigmoid')(X)\n\n    return X\n\ndef AutoEncoderModel(X_input):\n    autoencoder = Model(X_input, decoder(encoder(X_input)), name='AutoEncoderModel')\n    return autoencoder\n\n\ndef custom_loss(new, original):\n    reconstruct_loss = K.mean(K.square(new-original))\n    return reconstruct_loss\n\nX_input = Input(shape=(ModelConfig.H,ModelConfig.W,ModelConfig.SEQUENCE_SIZE,ModelConfig.C))\nautoEncoderModel = AutoEncoderModel(X_input)\nopt = Adam(lr=0.001)\nautoEncoderModel.compile(loss=custom_loss, optimizer=opt, metrics=['accuracy'])\nprint(autoEncoderModel.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:19.810833Z","iopub.execute_input":"2022-01-01T13:38:19.81157Z","iopub.status.idle":"2022-01-01T13:38:20.296371Z","shell.execute_reply.started":"2022-01-01T13:38:19.811533Z","shell.execute_reply":"2022-01-01T13:38:20.295342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.layers import Flatten,Dense, MaxPool3D, BatchNormalization\n\n\ndef create_classifier_model(ecoded):\n\n    X = Conv3D(filters=32, kernel_size=5, padding=\"same\", name=\"classifier_layer\")(ecoded)\n    X = MaxPool3D(pool_size=2)(X)\n\n    X = Conv3D(filters=16, kernel_size=3, padding=\"same\")(X)\n    \n    X = Conv3D(filters=8, kernel_size=2, padding=\"same\")(X)\n              \n    X = Flatten()(X)\n    X = Dense(256, activation='relu')(X)\n    X = BatchNormalization()(X)\n    X = Dense(len(ModelConfig.classes.items())+1, activation='softmax')(X)\n    #X = Dense(1, activation='sigmoid')(X)\n        \n    return X\n\nencoded = encoder(X_input)\nclassifier = Model(X_input,create_classifier_model(encoded))\nopt = Adam()\nloss = SparseCategoricalCrossentropy()\nclassifier.compile(loss=loss,\n                   optimizer=opt,\n                   metrics=['accuracy'])\nprint(classifier.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:20.369593Z","iopub.execute_input":"2022-01-01T13:38:20.370056Z","iopub.status.idle":"2022-01-01T13:38:20.727922Z","shell.execute_reply.started":"2022-01-01T13:38:20.370018Z","shell.execute_reply":"2022-01-01T13:38:20.72692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoEncoderModel.load_weights(\"../input/ucf-autoencoder-model-gray-lstm/UCF_autoencoder_model_GRAY_LSTM.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-01T13:38:20.730121Z","iopub.execute_input":"2022-01-01T13:38:20.730538Z","iopub.status.idle":"2022-01-01T13:38:20.902818Z","shell.execute_reply.started":"2022-01-01T13:38:20.730489Z","shell.execute_reply":"2022-01-01T13:38:20.901875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class classifier():\n    def __init__(self, generator):   \n        self.image_shape=(ModelConfig.H, ModelConfig.W, ModelConfig.SEQUENCE_SIZE, ModelConfig.C)        \n        X_input = Input(shape=(self.image_shape))\n        \n        self.init_classifier(X_input)\n        #self.set_classifier_layers(generator)\n    \n    def set_classifier_layers(self, generator):\n        for lc, lg in zip(self.classifier.layers, generator.layers):\n            if lg.name == \"decoder_layer\":\n                break\n            lc.set_weights(lg.get_weights())\n            lc.trainable = False\n        \n    def init_classifier(self, X_input):\n        encoded = encoder(X_input)\n        self.classifier = Model(X_input, create_classifier_model(encoded))\n        opt2 = Adam()\n        self.classifier.compile(loss=\"categorical_crossentropy\",\n                  optimizer=opt2,\n                  metrics=['accuracy'])\n#         self.classifier.compile(loss=\"binary_crossentropy\",\n#                   optimizer=opt2,\n#                   metrics=['accuracy'])\n        \n    def train(self, train_gen):\n        for epoch in range(ModelConfig.EPOCHS):\n            classify_loss_sum = 0   \n            classify_accuracy_sum = 0\n            classify_loss = 0\n            classify_accuracy = 0\n            progress_bar = Progbar(target=len(train_gen))\n            print(\"Epoch : \", epoch+1)\n            for i in range(len(train_gen)):\n                sample_classify_loss=0      \n                sample_classify_accuracy=0 \n                X_sample, y_sample = train_gen.get_mini_batch(i)\n                X_sample = X_sample[0]\n                X_sample_size = X_sample.shape[0]                \n                minibatch = None\n                j = 0\n                num_segments = 0\n                while j < X_sample_size:\n                    minibatch = []\n                    mini_batch_size = min(ModelConfig.BATCH_SIZE, X_sample_size-j)\n                    seg_indxes = list(range(j, j+mini_batch_size))\n                    minibatch = np.array([read_npz_file(X_sample[index]) for index in seg_indxes])\n                    y_true = np.array([y_sample for index in seg_indxes])\n                    y_true = y_true.reshape((y_true.shape[0], y_true.shape[2]))\n                    \n                    #print(y_true)\n                    #y_true = y_true.argmax(axis=1)\n                    #print(y_true)\n                    \n                    j+=mini_batch_size\n\n                    minibatch = np.transpose(minibatch, (0, 2, 3, 1, 4))\n                                      \n                    classify_loss, classify_accuracy = self.classifier.train_on_batch(minibatch,y_true)\n\n                    sample_classify_loss+=classify_loss     \n                    sample_classify_accuracy+=classify_accuracy\n                    \n                    num_segments += 1\n                clear_npz_directory(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)\n                \n                if i % 10 == 0:\n                    self.classifier.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.CLASSIFIER_MODEL_PATH))                   \n                \n                classify_loss_sum+=(sample_classify_loss/num_segments)\n                classify_accuracy_sum+=(sample_classify_accuracy/num_segments)\n                progress_bar.update(i+1, \n                                    values=[('classify_loss', (sample_classify_loss/num_segments)),\n                                            ('classify_acc', (sample_classify_accuracy/num_segments))])\n                print()\n\n            classify_loss=classify_loss_sum/len(train_gen)\n            classify_accuracy=classify_accuracy_sum/len(train_gen)\n\n            print(\"(^|^)  ('|')\")\n            print(\"%d [accuracy: %f ,loss: %f]\" % \n                  (epoch+1,                    \n                   classify_accuracy,\n                   classify_loss))\n            \n            self.classifier.save_weights(os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.CLASSIFIER_MODEL_PATH))\n            train_gen.on_epoch_end()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-01T14:02:58.817467Z","iopub.execute_input":"2022-01-01T14:02:58.81794Z","iopub.status.idle":"2022-01-01T14:02:58.839571Z","shell.execute_reply.started":"2022-01-01T14:02:58.817902Z","shell.execute_reply":"2022-01-01T14:02:58.838013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = classifier(autoEncoderModel)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T14:02:59.671862Z","iopub.execute_input":"2022-01-01T14:02:59.672595Z","iopub.status.idle":"2022-01-01T14:03:00.034471Z","shell.execute_reply.started":"2022-01-01T14:02:59.672541Z","shell.execute_reply":"2022-01-01T14:03:00.03345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classifier.classifier.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-01T14:03:00.056808Z","iopub.execute_input":"2022-01-01T14:03:00.057108Z","iopub.status.idle":"2022-01-01T14:03:00.077252Z","shell.execute_reply.started":"2022-01-01T14:03:00.057073Z","shell.execute_reply":"2022-01-01T14:03:00.076142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n\nwith tf.device(device_name):\n    classifier.train(train_gen)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T14:03:04.972833Z","iopub.execute_input":"2022-01-01T14:03:04.97316Z","iopub.status.idle":"2022-01-01T15:24:41.433069Z","shell.execute_reply.started":"2022-01-01T14:03:04.973126Z","shell.execute_reply":"2022-01-01T15:24:41.430787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}