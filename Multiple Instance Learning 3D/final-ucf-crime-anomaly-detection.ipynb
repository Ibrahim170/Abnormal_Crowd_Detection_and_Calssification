{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAPER : \n",
    "## Real-world Anomaly Detection in Surveillance Videos\n",
    "https://arxiv.org/pdf/1801.04264v3.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import sklearn.preprocessing\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import scipy.io as sio\n",
    "import sklearn.metrics\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.optimizers\n",
    "import scipy.io\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_height = 240\n",
    "frame_width = 320\n",
    "channels = 3\n",
    "frame_count = 16\n",
    "features_per_bag = 32\n",
    "normal_videos_path='C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/train/normal'\n",
    "abnormal_videos_path=r\"C:\\Users\\Administrator\\Desktop\\GP V2 Project\\Dataset\\Abnormal\\Abuse\"\n",
    "test_set=r\"C:\\Users\\Administrator\\Desktop\\GP Project\\Test_split\\test\"\n",
    "\n",
    "C3D_MEAN_PATH = 'https://github.com/adamcasson/c3d/releases/download/v0.1/c3d_mean.npy'\n",
    "\n",
    "raw_normal_train_features=\"C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/raw_c3d_features/raw_normal_train_features\"\n",
    "raw_abnormal_train_features='C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/raw_c3d_features/raw_abnormal_train_features'\n",
    "raw_test_features='C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/raw_c3d_features/raw_test_features'\n",
    "\n",
    "processed_normal_train_features=\"C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/processed_c3d_features/processed_normal_train_features\"\n",
    "processed_abnormal_train_features='C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/processed_c3d_features/processed_abnormal_train_features'\n",
    "processed_test_features=\"C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/processed_c3d_features/processed_test_features\"\n",
    "\n",
    "trained_models=r\"C:\\Users\\Administrator\\Desktop\\GP Project\\trained_models_final\"\n",
    "preds_folder=r\"C:\\Users\\Administrator\\Desktop\\GP Project\\Test_split\\preds_folder\"\n",
    "test_temporal_annotations=r\"C:\\Users\\Administrator\\Desktop\\GP Project\\Test_split\\temporal-annotation.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_anomaly=r\"C:\\Users\\Administrator\\Desktop\\GP Project\\crimeucfdataset\\Dataset\\processed_c3d_features\\processed_abnormal_train_features\"\n",
    "\n",
    "file_name_list = []\n",
    "file_path_list = []\n",
    "file_type_list = []\n",
    "file_class_list = []\n",
    "file_npy_path_list = []\n",
    "\n",
    "classes = {\"Normal\":0, \"Abbuse\":1,\"Arrest\":2,\"Arson\":3,\"Assault\":4,\"Explosion\":6, 'Burglary':5, 'Fighting':7,\"RoadAccidents\":8\n",
    "          ,\"Robbery\":9,\"Shooting\":10,\"ShopLifting\":11,\"Stealing\":12,\"Vandalism\":13}\n",
    "types = {\"Normal\":0, \"Abnormal\":1}\n",
    "def build_dataset_df():\n",
    "    global file_name_list \n",
    "    global file_path_list\n",
    "    global file_type_list \n",
    "    global file_class_list \n",
    "    global file_npy_path_list\n",
    "\n",
    "    file_name_list.clear()\n",
    "    file_path_list.clear()\n",
    "    file_type_list.clear()\n",
    "    file_class_list.clear()\n",
    "    file_npy_path_list.clear()\n",
    "\n",
    "\n",
    "    for root, subdirs, files in os.walk(processed_anomaly):\n",
    "        for filename in files:\n",
    "            \n",
    "\n",
    "            file_path = os.path.join(root, filename)\n",
    "            file_name = filename.split('.')[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            file_name_list.append(file_name)\n",
    "            file_path_list.append(file_path)\n",
    "            file_class = file_path.split('\\\\')[-2]\n",
    "            #print(file_class)\n",
    "            if file_class in classes.keys():\n",
    "                file_type_list.append(types[\"Abnormal\"])\n",
    "                file_class_list.append(classes[file_class])\n",
    "            else:\n",
    "                file_type_list.append(types[\"Normal\"])\n",
    "                file_class_list.append(classes[\"Normal\"])\n",
    "\n",
    "            #npy_path = Save2Npy(file_path, file_name, Config.save_npy_dir)\n",
    "            #file_npy_path_list.append(npy_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dataset_df()\n",
    "dataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list)),\n",
    "                          columns =['file_name', 'file_path', 'file_type', 'file_class'])\n",
    "print(len(file_path_list), len(file_name_list), len(file_type_list), len(file_class_list))\n",
    "dataset_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['file_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prerocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window(arr, size, stride):\n",
    "    \"\"\"Apply sliding window to an array, getting chunks of\n",
    "    of specified size using the specified stride\n",
    "    :param arr: Array to be divided\n",
    "    :param size: Size of the chunks\n",
    "    :param stride: Number of frames to skip for the next chunk\n",
    "    :returns: Tensor with the resulting chunks\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    num_chunks = int((len(arr) - size) / stride) + 2\n",
    "    result = []\n",
    "    for i in range(0,  num_chunks * stride, stride):\n",
    "        if len(arr[i:i + size]) > 0:\n",
    "            result.append(arr[i:i + size])\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def interpolate(features, features_per_bag):\n",
    "    \"\"\"Transform a bag with an arbitrary number of features into a bag\n",
    "    with a fixed amount, using interpolation of consecutive features\n",
    "    :param features: Bag of features to pad\n",
    "    :param features_per_bag: Number of features to obtain\n",
    "    :returns: Interpolated features\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    feature_size = np.array(features).shape[1]\n",
    "    interpolated_features = np.zeros((features_per_bag, feature_size))\n",
    "    interpolation_indices = np.round(np.linspace(0, len(features) - 1, num=features_per_bag + 1))\n",
    "    count = 0\n",
    "    for index in range(0, len(interpolation_indices)-1):\n",
    "        start = int(interpolation_indices[index])\n",
    "        end = int(interpolation_indices[index + 1])\n",
    "\n",
    "        assert end >= start\n",
    "\n",
    "        if start == end:\n",
    "            temp_vect = features[start, :]\n",
    "        else:\n",
    "            temp_vect = np.mean(features[start:end+1, :], axis=0)\n",
    "\n",
    "        temp_vect = temp_vect / np.linalg.norm(temp_vect)\n",
    "\n",
    "        if np.linalg.norm(temp_vect) == 0:\n",
    "            print(\"Error\")\n",
    "\n",
    "        interpolated_features[count,:]=temp_vect\n",
    "        count = count + 1\n",
    "\n",
    "    return np.array(interpolated_features)\n",
    "\n",
    "\n",
    "def extrapolate(outputs, num_frames):\n",
    "    \"\"\"Expand output to match the video length\n",
    "    :param outputs: Array of predicted outputs\n",
    "    :param num_frames: Expected size of the output array\n",
    "    :returns: Array of output size\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    extrapolated_outputs = []\n",
    "    extrapolation_indices = np.round(np.linspace(0, len(outputs) - 1, num=num_frames))\n",
    "    for index in extrapolation_indices:\n",
    "        extrapolated_outputs.append(outputs[int(index)])\n",
    "    return np.array(extrapolated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_clips(video_path):\n",
    "    \"\"\"Divides the input video into non-overlapping clips\n",
    "    :param video_path: Path to the video\n",
    "    :returns: Array with the fragments of video\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    frames = get_video_frames(video_path)\n",
    "    clips = sliding_window(frames, frame_count, frame_count)\n",
    "    return clips, len(frames)\n",
    "\n",
    "\n",
    "def get_video_frames(video_path):\n",
    "    \"\"\"Reads the video given a file path\n",
    "    :param video_path: Path to the video\n",
    "    :returns: Video as an array of frames\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_input(video):\n",
    "    \"\"\"Preprocess video input to make it suitable for feature extraction.\n",
    "    The video is resized, cropped, resampled and training mean is substracted\n",
    "    to make it suitable for the network\n",
    "    :param video: Video to be processed\n",
    "    :returns: Preprocessed video\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    intervals = np.ceil(np.linspace(0, video.shape[0] - 1, 16)).astype(int)\n",
    "    frames = video[intervals]\n",
    "\n",
    "    # Reshape to 128x171\n",
    "    reshape_frames = np.zeros((frames.shape[0], 128, 171, frames.shape[3]))\n",
    "    for i, img in enumerate(frames):\n",
    "        img = cv2.resize(img, (171, 128), cv2.INTER_CUBIC)\n",
    "        reshape_frames[i, :, :, :] = img\n",
    "\n",
    "    mean_path = tf.keras.utils.get_file('c3d_mean.npy',\n",
    "                         C3D_MEAN_PATH,\n",
    "                         cache_subdir='models',\n",
    "                         md5_hash='08a07d9761e76097985124d9e8b2fe34')\n",
    "\n",
    "    mean = np.load(mean_path)\n",
    "    reshape_frames -= mean\n",
    "    # Crop to 112x112\n",
    "    reshape_frames = reshape_frames[:, 8:120, 30:142, :]\n",
    "    # Add extra dimension for samples\n",
    "    reshape_frames = np.expand_dims(reshape_frames, axis=0)\n",
    "\n",
    "    return reshape_frames\n",
    "\n",
    "\n",
    "def C3D(weights='sports1M'):\n",
    "    \"\"\"Creation of the full C3D architecture\n",
    "    :param weights: Weights to be loaded into the network. If None,\n",
    "    the network is randomly initialized.\n",
    "    :returns: Network model\n",
    "    :rtype: keras.model\n",
    "    \"\"\"\n",
    "\n",
    "    if weights not in {'sports1M', None}:\n",
    "        raise ValueError('weights should be either be sports1M or None')\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "        shape = (16, 112, 112, 3)\n",
    "    else:\n",
    "        shape = (3, 16, 112, 112)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv3D(64,3,activation='relu',padding='same',name='conv1', input_shape=shape))\n",
    "    model.add( MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),padding='same', name='pool1'))\n",
    "\n",
    "    model.add(Conv3D(128, 3, activation='relu', padding='same', name='conv2'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2),strides=(2, 2, 2),padding='valid',name='pool2'))\n",
    "\n",
    "    model.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3a'))\n",
    "    model.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3b'))\n",
    "    model.add(\n",
    "        MaxPooling3D(pool_size=(2, 2, 2),\n",
    "                     strides=(2, 2, 2),\n",
    "                     padding='valid',\n",
    "                     name='pool3'))\n",
    "\n",
    "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4a'))\n",
    "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4b'))\n",
    "    model.add(\n",
    "        MaxPooling3D(pool_size=(2, 2, 2),\n",
    "                     strides=(2, 2, 2),\n",
    "                     padding='valid',\n",
    "                     name='pool4'))\n",
    "\n",
    "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5a'))\n",
    "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5b'))\n",
    "    model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "    model.add(\n",
    "        MaxPooling3D(pool_size=(2, 2, 2),\n",
    "                     strides=(2, 2, 2),\n",
    "                     padding='valid',\n",
    "                     name='pool5'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(487, activation='softmax', name='fc8'))\n",
    "\n",
    "    if weights == 'sports1M':\n",
    "        model.load_weights('C:/Users/Administrator/Desktop/GP Project/c3d_sports1m.h5')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def c3d_feature_extractor():\n",
    "    \"\"\"Creation of the feature extraction architecture. This network is\n",
    "    formed by a subset of the original C3D architecture (from the\n",
    "    beginning to fc6 layer)\n",
    "    :returns: Feature extraction model\n",
    "    :rtype: keras.model\n",
    "    \"\"\"\n",
    "    model = C3D(weights='sports1M')\n",
    "    layer_name = 'fc6'\n",
    "    feature_extractor_model = Model(inputs=model.input,\n",
    "                                    outputs=model.get_layer(layer_name).output)\n",
    "    return feature_extractor_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: Feature Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Raw Normal Train _ features \n",
    "feature_extractor = c3d_feature_extractor()\n",
    "normal_videos = os.listdir(normal_videos_path)\n",
    "normal_videos.sort()\n",
    "\n",
    "print(\"Processing normal videos...\")\n",
    "for vid_name in normal_videos:\n",
    "    print(\"Processing {}\".format(vid_name))\n",
    "    vid_path = os.path.join(normal_videos_path, vid_name)\n",
    "    feats_path = os.path.join(\n",
    "        raw_normal_train_features, vid_name + \".npy\"\n",
    "    )\n",
    "\n",
    "    clips, frames = get_video_clips(vid_path)\n",
    "\n",
    "    # Remove last clip if number of frames is not equal to 16\n",
    "    if frames % 16 != 0:\n",
    "        clips = clips[:-1]\n",
    "\n",
    "    prep_clips = [preprocess_input(np.array(clip)) for clip in clips]\n",
    "    prep_clips = np.vstack(prep_clips)\n",
    "\n",
    "    features = feature_extractor.predict(prep_clips)\n",
    "    features = sklearn.preprocessing.normalize(features, axis=1)\n",
    "\n",
    "    with open(feats_path, \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abnormal Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Abnormal Videos:\n",
    "feature_extractor = c3d_feature_extractor()\n",
    "abnormal_videos = os.listdir(abnormal_videos_path)\n",
    "abnormal_videos.sort()\n",
    "print(\"Processing abnormal videos...\")\n",
    "for vid_name in abnormal_videos:\n",
    "    print(\"Processing {}\".format(vid_name))\n",
    "    vid_path = os.path.join(abnormal_videos_path, vid_name)\n",
    "    feats_path = os.path.join(\n",
    "       raw_abnormal_train_features, vid_name + \".npy\"\n",
    "    )\n",
    "\n",
    "    clips, frames = get_video_clips(vid_path)\n",
    "\n",
    "    # Remove last clip if number of frames is not equal to 16\n",
    "    if frames % 16 != 0:\n",
    "        clips = clips[:-1]\n",
    "\n",
    "    prep_clips = [preprocess_input(np.array(clip)) for clip in clips]\n",
    "    prep_clips = np.vstack(prep_clips)\n",
    "\n",
    "    features = feature_extractor.predict(prep_clips)\n",
    "    features = sklearn.preprocessing.normalize(features, axis=1)\n",
    "\n",
    "    with open(feats_path, \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T05:14:05.230745Z",
     "iopub.status.busy": "2021-12-19T05:14:05.23022Z",
     "iopub.status.idle": "2021-12-19T05:14:05.235527Z",
     "shell.execute_reply": "2021-12-19T05:14:05.234447Z",
     "shell.execute_reply.started": "2021-12-19T05:14:05.230704Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test set\n",
    "feature_extractor = c3d_feature_extractor()\n",
    "test_videos = os.listdir(test_set)\n",
    "test_videos.sort()\n",
    "print(\"Processing test videos...\")\n",
    "for vid_name in test_videos:\n",
    "    print(\"Processing {}\".format(vid_name))\n",
    "    vid_path = os.path.join(test_set, vid_name)\n",
    "    feats_path = os.path.join(raw_test_features, vid_name[:-9] + \".npy\")\n",
    "\n",
    "    clips, frames = get_video_clips(vid_path)\n",
    "\n",
    "    # Remove last clip if number of frames is not equal to 16\n",
    "    if frames % 16 != 0:\n",
    "        clips = clips[:-1]\n",
    "\n",
    "    prep_clips = [preprocess_input(np.array(clip)) for clip in clips]\n",
    "    prep_clips = np.vstack(prep_clips)\n",
    "\n",
    "    features = feature_extractor.predict(prep_clips)\n",
    "    features = sklearn.preprocessing.normalize(features, axis=1)\n",
    "\n",
    "    with open(feats_path, \"wb\") as f:\n",
    "        np.save(f, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing : Transform videos into segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T05:18:20.973328Z",
     "iopub.status.busy": "2021-12-19T05:18:20.972885Z",
     "iopub.status.idle": "2021-12-19T05:18:21.155982Z",
     "shell.execute_reply": "2021-12-19T05:18:21.155231Z",
     "shell.execute_reply.started": "2021-12-19T05:18:20.973288Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_into_segments(features, n_segments=32):\n",
    "    if features.shape[0] < n_segments:\n",
    "        raise RuntimeError(\n",
    "            \"Number of prev segments lesser than expected output size\"\n",
    "        )\n",
    "\n",
    "    cuts = np.linspace(0, features.shape[0], n_segments,\n",
    "                       dtype=int, endpoint=False)\n",
    "\n",
    "    new_feats = []\n",
    "    for i, j in zip(cuts[:-1], cuts[1:]):\n",
    "        new_feats.append(np.mean(features[i:j,:], axis=0))\n",
    "\n",
    "    new_feats.append(np.mean(features[cuts[-1]:,:], axis=0))\n",
    "\n",
    "    new_feats = np.array(new_feats)\n",
    "    new_feats = sklearn.preprocessing.normalize(new_feats, axis=1)\n",
    "    return new_feats\n",
    "\n",
    "# for filename in os.listdir(raw_normal_train_features):\n",
    "#     print(\"Processing {}\".format(filename))\n",
    "#     raw_file_path = os.path.join(\n",
    "#         raw_normal_train_features, filename\n",
    "#     )\n",
    "#     processed_file_path = os.path.join(\n",
    "#         processed_normal_train_features, filename\n",
    "#     )\n",
    "\n",
    "#     with open(raw_file_path, \"rb\") as f:\n",
    "#         feats = np.load(f, allow_pickle=True)\n",
    "\n",
    "#     try:\n",
    "#         new_feats = transform_into_segments(feats)\n",
    "#         with open(processed_file_path, \"wb\") as f:\n",
    "#             np.save(f, new_feats, allow_pickle=True)\n",
    "#     except RuntimeError:\n",
    "#         print(\"Video {} too short\".format(filename))\n",
    "\n",
    "# for filename in os.listdir(raw_abnormal_train_features):\n",
    "#     print(\"Processing {}\".format(filename))\n",
    "#     raw_file_path = os.path.join(\n",
    "#         raw_abnormal_train_features, filename\n",
    "#     )\n",
    "#     processed_file_path = os.path.join(\n",
    "#         processed_abnormal_train_features, filename\n",
    "#     )\n",
    "#     with open(raw_file_path, \"rb\") as f:\n",
    "#         feats = np.load(f, allow_pickle=True)\n",
    "\n",
    "#     try:\n",
    "#         new_feats = transform_into_segments(feats)\n",
    "#         with open(processed_file_path, \"wb\") as f:\n",
    "#             np.save(f, new_feats, allow_pickle=True)\n",
    "#     except RuntimeError:\n",
    "#         print(\"Video {} too short\".format(filename))\n",
    "\n",
    "for filename in os.listdir(raw_test_features):\n",
    "    print(\"Processing {}\".format(filename))\n",
    "    raw_file_path = os.path.join(\n",
    "        raw_test_features, filename\n",
    "    )\n",
    "    processed_file_path = os.path.join(\n",
    "        processed_test_features, filename\n",
    "    )\n",
    "    with open(raw_file_path, \"rb\") as f:\n",
    "        feats = np.load(f, allow_pickle=True)\n",
    "\n",
    "    try:\n",
    "        new_feats = transform_into_segments(feats)\n",
    "        with open(processed_file_path, \"wb\") as f:\n",
    "            np.save(f, new_feats, allow_pickle=True)\n",
    "    except RuntimeError:\n",
    "        print(\"Video {} too short\".format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T11:27:05.519222Z",
     "iopub.status.busy": "2021-12-19T11:27:05.518686Z",
     "iopub.status.idle": "2021-12-19T11:27:05.589949Z",
     "shell.execute_reply": "2021-12-19T11:27:05.589272Z",
     "shell.execute_reply.started": "2021-12-19T11:27:05.519184Z"
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4096,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2/ipykernel_7032/396057323.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_classifier_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;31m#model=classifier_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2/ipykernel_7032/396057323.py\u001b[0m in \u001b[0;36mbuild_classifier_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"C:\\Users\\Administrator\\Desktop\\GP Project\\trained_models_final\\weights.mat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2/ipykernel_7032/396057323.py\u001b[0m in \u001b[0;36mclassifier_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     model.add(Dense(512, input_dim=4096, kernel_initializer='glorot_normal',\n\u001b[0m\u001b[0;32m      8\u001b[0m                     kernel_regularizer=l2(0.001), activation='relu'))\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_2.7\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_2.7\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_2.7\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[1;34m(self, shape, mean, stddev, dtype)\u001b[0m\n\u001b[0;32m   1839\u001b[0m       return self._generator.truncated_normal(\n\u001b[0;32m   1840\u001b[0m           shape=shape, mean=mean, stddev=stddev, dtype=dtype)\n\u001b[1;32m-> 1841\u001b[1;33m     return tf.random.truncated_normal(\n\u001b[0m\u001b[0;32m   1842\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         seed=self.make_legacy_seed())\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4096,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def classifier_model():\n",
    "    \"\"\"Build the classifier\n",
    "    :returns: Classifier model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=4096, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    \n",
    "    model.add(Dense(256, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dense(32, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001), activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Original Model :\n",
    "def classifier_model_o():\n",
    "    \"\"\"Build the classifier\n",
    "    :returns: Classifier model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=4096, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    \n",
    "    model.add(Dense(32, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal',\n",
    "                    kernel_regularizer=l2(0.001), activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def build_classifier_model():\n",
    "    \"\"\"Build the classifier and load the pretrained weights\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    model = classifier_model()\n",
    "    model = load_weights(model, r\"C:\\Users\\Administrator\\Desktop\\GP Project\\trained_models_final\\weights.mat\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_classifier_model_o():\n",
    "    \"\"\"Build the classifier and load the pretrained weights\n",
    "    :returns:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    model = classifier_model_o()\n",
    "    model = load_weights(model, 'C:/Users/Administrator/Desktop/GP Project/weights_L1L2.mat')\n",
    "    return model\n",
    "\n",
    "def conv_dict(dict2):\n",
    "    \"\"\"Prepare the dictionary of weights to be loaded by the network\n",
    "    :param dict2: Dictionary to format\n",
    "    :returns: The dictionary properly formatted\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    dict = {}\n",
    "    for i in range(len(dict2)):\n",
    "        if str(i) in dict2:\n",
    "            if dict2[str(i)].shape == (0, 0):\n",
    "                dict[str(i)] = dict2[str(i)]\n",
    "            else:\n",
    "                weights = dict2[str(i)][0]\n",
    "                weights2 = []\n",
    "                for weight in weights:\n",
    "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
    "                        weights2.append(weight[0])\n",
    "                    else:\n",
    "                        weights2.append(weight)\n",
    "                dict[str(i)] = weights2\n",
    "    return dict\n",
    "\n",
    "\n",
    "def load_weights(model, weights_file):\n",
    "    \"\"\"Loads the pretrained weights into the network architecture\n",
    "    :param model: keras model of the network\n",
    "    :param weights_file: Path to the weights file\n",
    "    :returns: The input model with the weights properly loaded\n",
    "    :rtype: keras.model\n",
    "    \"\"\"\n",
    "    dict2 = sio.loadmat(weights_file)\n",
    "    dict = conv_dict(dict2)\n",
    "    i = 0\n",
    "    for layer in model.layers:\n",
    "        weights = dict[str(i)]\n",
    "        layer.set_weights(weights)\n",
    "        i += 1\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = build_classifier_model()\n",
    "    #model=classifier_model()\n",
    "    model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_normal_train_features=\"C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/processed_c3d_features/processed_normal_train_features\"\n",
    "\n",
    "processed_abnormal_train_features='C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/processed_c3d_features/processed_abnormal_train_features'\n",
    "processed_test_features=\"C:/Users/Administrator/Desktop/GP Project/crimeucfdataset/Dataset/processed_c3d_features/processed_test_features\"\n",
    "\n",
    "normal_list = os.listdir(processed_normal_train_features)\n",
    "normal_list.sort()\n",
    "abnormal_list = os.listdir(processed_abnormal_train_features)\n",
    "abnormal_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T10:34:58.518161Z",
     "iopub.status.busy": "2021-12-19T10:34:58.517610Z",
     "iopub.status.idle": "2021-12-19T10:59:02.541993Z",
     "shell.execute_reply": "2021-12-19T10:59:02.541196Z",
     "shell.execute_reply.started": "2021-12-19T10:34:58.518127Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, json_path, weight_path):\n",
    "    json_string = model.to_json()\n",
    "    open(json_path, 'w').write(json_string)\n",
    "    \n",
    "    dict = {}\n",
    "    i = 0\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        my_list = np.zeros(len(weights), dtype=np.object)\n",
    "        my_list[:] = weights\n",
    "        dict[str(i)] = my_list\n",
    "        i += 1\n",
    "    scipy.io.savemat(weight_path, dict)\n",
    "\n",
    "def load_model(json_path):\n",
    "    model = model_from_json(open(json_path).read())\n",
    "    return model\n",
    "\n",
    "def load_batch_train(normal_path, normal_list, abnormal_path, abnormal_list):\n",
    "\n",
    "    batchsize=60\n",
    "    n_exp = int(batchsize/2)\n",
    "\n",
    "    num_normal = len(normal_list)\n",
    "    num_abnormal = len(abnormal_list)\n",
    "\n",
    "    abnor_list_idx = np.random.permutation(num_abnormal)\n",
    "    abnor_list = abnor_list_idx[:n_exp]\n",
    "    norm_list_idx = np.random.permutation(num_normal)\n",
    "    norm_list = norm_list_idx[:n_exp]\n",
    "\n",
    "    abnormal_feats = []\n",
    "    for video_idx in abnor_list:\n",
    "        video_path = os.path.join(abnormal_path, abnormal_list[video_idx])\n",
    "        with open(video_path, \"rb\") as f:\n",
    "            feats = np.load(f)\n",
    "        abnormal_feats.append(feats)\n",
    "\n",
    "    normal_feats = []\n",
    "    for video_idx in norm_list:\n",
    "        video_path = os.path.join(normal_path, normal_list[video_idx])\n",
    "        with open(video_path, \"rb\") as f:\n",
    "            feats = np.load(f)\n",
    "        normal_feats.append(feats)\n",
    "        \n",
    "\n",
    "    all_feats = np.vstack((*abnormal_feats, *normal_feats))\n",
    "    all_labels = np.zeros(32*batchsize, dtype='uint8')\n",
    "\n",
    "    all_labels[:32*n_exp] = 1\n",
    "\n",
    "    return  all_feats, all_labels\n",
    "\n",
    "\n",
    "def custom_objective(y_true, y_pred):\n",
    "\n",
    "    y_true = K.reshape(y_true, [-1])\n",
    "    y_pred = K.reshape(y_pred, [-1])\n",
    "    n_seg = 32\n",
    "    nvid = 60\n",
    "    n_exp = int(nvid / 2)\n",
    "\n",
    "    max_scores_list = []\n",
    "    z_scores_list = []\n",
    "    temporal_constrains_list = []\n",
    "    sparsity_constrains_list = []\n",
    "\n",
    "    for i in range(0, n_exp, 1):\n",
    "\n",
    "        video_predictions = y_pred[i*n_seg:(i+1)*n_seg]\n",
    "\n",
    "        max_scores_list.append(K.max(video_predictions))\n",
    "        temporal_constrains_list.append(\n",
    "            K.sum(K.pow(video_predictions[1:] - video_predictions[:-1], 2))\n",
    "        )\n",
    "        sparsity_constrains_list.append(K.sum(video_predictions))\n",
    "\n",
    "    for j in range(n_exp, 2*n_exp, 1):\n",
    "\n",
    "        video_predictions = y_pred[j*n_seg:(j+1)*n_seg]\n",
    "        max_scores_list.append(K.max(video_predictions))\n",
    "\n",
    "    max_scores = K.stack(max_scores_list)\n",
    "    temporal_constrains = K.stack(temporal_constrains_list)\n",
    "    sparsity_constrains = K.stack(sparsity_constrains_list)\n",
    "\n",
    "    for ii in range(0, n_exp, 1):\n",
    "        max_z = K.maximum(1 - max_scores[:n_exp] + max_scores[n_exp+ii], 0)\n",
    "        z_scores_list.append(K.sum(max_z))\n",
    "\n",
    "    z_scores = K.stack(z_scores_list)\n",
    "    z = K.mean(z_scores)\n",
    "\n",
    "    return z + \\\n",
    "        0.00008*K.sum(temporal_constrains) + \\\n",
    "        0.00008*K.sum(sparsity_constrains)\n",
    "\n",
    "\n",
    "output_dir = trained_models\n",
    "normal_dir = processed_normal_train_features\n",
    "abnormal_dir = processed_abnormal_train_features\n",
    "\n",
    "normal_list = os.listdir(normal_dir)\n",
    "normal_list.sort()\n",
    "abnormal_list = os.listdir(abnormal_dir)\n",
    "abnormal_list.sort()\n",
    "\n",
    "weights_path = output_dir + 'weights.mat'\n",
    "\n",
    "model_path = output_dir + 'model.json'\n",
    "\n",
    "#Create Full connected Model\n",
    "model = classifier_model()\n",
    "\n",
    "adagrad = tf.keras.optimizers.Adagrad(learning_rate=0.001, epsilon=1e-08)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=1e-08)\n",
    "\n",
    "model.compile(loss=custom_objective, optimizer=adagrad)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "       os.makedirs(output_dir)\n",
    "\n",
    "loss_graph =[]\n",
    "num_iters = 25000\n",
    "total_iterations = 0\n",
    "batchsize=60\n",
    "time_before = datetime.now()\n",
    "\n",
    "\n",
    "for it_num in range(num_iters):\n",
    "    inputs, targets = load_batch_train(\n",
    "        normal_dir, normal_list, abnormal_dir, abnormal_list\n",
    "    )\n",
    "    batch_loss = model.train_on_batch(inputs, targets)\n",
    "    loss_graph = np.hstack((loss_graph, batch_loss))\n",
    "    total_iterations += 1\n",
    "    if total_iterations % 20 == 0:\n",
    "        print (\"Iteration={} took: {}, loss: {}\".format(\n",
    "            total_iterations, datetime.now() - time_before, batch_loss)\n",
    "        )\n",
    "        #iteration_path = output_dir + 'Iterations_graph_' + str(total_iterations) + '.mat'\n",
    "       # scipy.io.savemat(iteration_path, dict(loss_graph=loss_graph))\n",
    "#     if total_iterations % 1000 == 0:  # Save the model at every 1000th iterations.\n",
    "#         weights_path = output_dir + 'weightsAnomalyL1L2_' + str(total_iterations) + '.mat'\n",
    "#         save_model(model, model_path, weights_path)\n",
    "\n",
    "print(\"Train Successful - Model saved\")\n",
    "save_model(model, model_path, weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_Dataset training :\n",
    "\n",
    "def load_test_set(videos_path, videos_list):\n",
    "    feats = []\n",
    "    \n",
    "    for vid in videos_list:\n",
    "        vid_path = os.path.join(videos_path, vid)\n",
    "        with open(vid_path, \"rb\") as f:\n",
    "            feat = np.load(f)\n",
    "        feats.append(feat)\n",
    "\n",
    "    feats = np.array(feats)\n",
    "    return feats\n",
    "\n",
    "classifier_model = build_classifier_model()\n",
    "\n",
    "vid_list = os.listdir(processed_test_features)\n",
    "vid_list.sort()\n",
    "\n",
    "test_set = load_test_set(processed_test_features, vid_list)\n",
    "\n",
    "for filename, example in zip(vid_list, test_set):\n",
    "    predictions_file = filename[:-4] + '.npy'\n",
    "    pred_path = os.path.join(preds_folder, predictions_file)\n",
    "    pred = classifier_model.predict_on_batch(example)\n",
    "    with open(pred_path, \"wb\") as f:\n",
    "        np.save(pred_path, pred, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def eer_score(fpr, tpr, thr):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    fnr = 1-tpr\n",
    "    abs_diffs = np.abs(fpr - fnr)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((fpr[min_index], fnr[min_index]))\n",
    "    return eer, thr[min_index]\n",
    "\n",
    "ground_truth = pd.read_csv(\n",
    "    test_temporal_annotations, header=None, index_col=0\n",
    ")\n",
    "\n",
    "preds = []\n",
    "gts = []\n",
    "\n",
    "for idx, row in ground_truth.iterrows():\n",
    "    preds_file_path = os.path.join(preds_folder, idx)\n",
    "    frames = row[6]\n",
    "    try:\n",
    "        with open(preds_file_path, \"rb\") as f:\n",
    "            curr_preds = np.load(f)\n",
    "\n",
    "        padded_preds = extrapolate(curr_preds, frames)\n",
    "    except FileNotFoundError:\n",
    "        padded_preds = np.zeros((frames,1))\n",
    "        print(\"No predictions generated for {}\".format(idx))\n",
    "\n",
    "    curr_gts = np.zeros(frames)\n",
    "    anomaly_start_1 =  row[2]\n",
    "    anomaly_end_1 = row[3]\n",
    "\n",
    "    anomaly_start_2 =  row[4]\n",
    "    anomaly_end_2 = row[5]\n",
    "\n",
    "    if anomaly_start_1 != -1 and anomaly_end_1 != -1:\n",
    "        curr_gts[anomaly_start_1:anomaly_end_1+1] = 1\n",
    "\n",
    "    if anomaly_start_2 != -1 and anomaly_end_2 != -1:\n",
    "        curr_gts[anomaly_start_2:anomaly_end_2+1] = 1\n",
    "\n",
    "    preds.append(padded_preds)\n",
    "    gts.append(curr_gts)\n",
    "\n",
    "gts = np.concatenate(gts)\n",
    "preds = np.concatenate(preds)\n",
    "preds_labels = np.round(preds)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(gts, preds_labels)\n",
    "ap = sklearn.metrics.average_precision_score(gts, preds)\n",
    "f1 = sklearn.metrics.f1_score(gts, preds_labels)\n",
    "fpr, tpr, thr = sklearn.metrics.roc_curve(gts, preds)\n",
    "prec, rec, _ = sklearn.metrics.precision_recall_curve(gts, preds)\n",
    "eer, _ = eer_score(fpr, tpr, thr)\n",
    "conf_mat = sklearn.metrics.confusion_matrix(gts, preds_labels)\n",
    "auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title(\"Curve ROC\")\n",
    "plt.plot(fpr, tpr, 'b', label = \"AUC: {}\".format(auc))\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig(os.path.join(output_folder, \"roc.png\"))\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.title(\"Curve Rec-Prec\")\n",
    "plt.plot(rec, prec, 'b', label = \"Original - AP: {:.5f}\".format(ap))\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Precison')\n",
    "plt.xlabel('Recall')\n",
    "plt.savefig(os.path.join(output_folder, \"pr_curve.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: {:.5f}, AUC: {:.5f}, F1: {:.5f}, EER: {:.5f}, AP: {:.5F}\".format(\n",
    "    acc, auc, f1, eer, ap\n",
    "))\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T11:29:54.422135Z",
     "iopub.status.busy": "2021-12-19T11:29:54.421323Z",
     "iopub.status.idle": "2021-12-19T11:29:54.439743Z",
     "shell.execute_reply": "2021-12-19T11:29:54.438958Z",
     "shell.execute_reply.started": "2021-12-19T11:29:54.422085Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "\n",
    "def visualize_clip(clip, convert_bgr=False, save_gif=False, file_path=None):\n",
    "    num_frames = len(clip)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    def update(i):\n",
    "        if convert_bgr:\n",
    "            frame = cv2.cvtColor(clip[i], cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            frame = clip[i]\n",
    "        plt.imshow(frame)\n",
    "        return plt\n",
    "\n",
    "    # FuncAnimation will call the 'update' function for each frame; here\n",
    "    # animating over 10 frames, with an interval of 20ms between frames.\n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0, num_frames), interval=1)\n",
    "    if save_gif:\n",
    "        anim.save(file_path, dpi=80, writer='imagemagick')\n",
    "    else:\n",
    "        # plt.show() will just loop the animation forever.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def visualize_predictions_full(video_path, predictions, save_path):\n",
    "    frames = get_video_frames(video_path)\n",
    "    assert len(frames) == len(predictions)\n",
    "    anomaly=[]\n",
    "    label=0\n",
    "    prob=0\n",
    "    for n in predictions:\n",
    "        if n>=0.6:\n",
    "            anomaly.append(n)\n",
    "        if len(anomaly)>6:\n",
    "            \n",
    "            label='Anomaly'\n",
    "            prob=np.mean(anomaly)\n",
    "        else:\n",
    "            label='Normal'\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    fig_frame = plt.subplot(2, 1, 1)\n",
    "    fig_prediction = plt.subplot(2, 1, 2)\n",
    "    fig_prediction.set_xlim(0, len(frames))\n",
    "    fig_prediction.set_ylim(0, 1.15)\n",
    "    fig_prediction.set_title('{}:({:.4f})'.format(label, prob))\n",
    "    \n",
    "    \n",
    "    def update(i):\n",
    "        frame = frames[i]\n",
    "        x = range(0, i)\n",
    "        y = predictions[0:i]\n",
    "        fig_prediction.plot(x, y, '-')\n",
    "        fig_frame.imshow(frame)\n",
    "        return plt\n",
    "\n",
    "    # FuncAnimation will call the 'update' function for each frame; here\n",
    "    # animating over 10 frames, with an interval of 20ms between frames.\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0, len(frames), 10), interval=1, repeat=False)\n",
    "\n",
    "    if save_path:\n",
    "           \n",
    "        f=save_path\n",
    "        writervideo = animation.FFMpegWriter(fps=16) \n",
    "        anim.save(f, writer=writervideo)\n",
    "    else:\n",
    "           plt.show()\n",
    "   \n",
    "    return anim\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T11:41:40.981283Z",
     "iopub.status.busy": "2021-12-19T11:41:40.980720Z",
     "iopub.status.idle": "2021-12-19T11:41:40.986291Z",
     "shell.execute_reply": "2021-12-19T11:41:40.985665Z",
     "shell.execute_reply.started": "2021-12-19T11:41:40.981246Z"
    }
   },
   "outputs": [],
   "source": [
    "output_folder='C:/Users/Administrator/Desktop/GP Project/output_folder_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-19T11:42:30.033142Z",
     "iopub.status.busy": "2021-12-19T11:42:30.032852Z",
     "iopub.status.idle": "2021-12-19T11:42:52.849172Z",
     "shell.execute_reply": "2021-12-19T11:42:52.848387Z",
     "shell.execute_reply.started": "2021-12-19T11:42:30.033112Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_demo():\n",
    "    sample_video_path=r\"C:\\Users\\Administrator\\Desktop\\GP Project\\Test_split\\test\\Normal_Videos_941_x264.mp4\"\n",
    "\n",
    "    video_name = os.path.basename(sample_video_path).split('.')[0]\n",
    "\n",
    "    # read video\n",
    "    video_clips, num_frames = get_video_clips(sample_video_path)\n",
    "\n",
    "    print(\"Number of clips in the video : \", len(video_clips))\n",
    "\n",
    "    # build models\n",
    "    feature_extractor = c3d_feature_extractor()\n",
    "    classifier_model = build_classifier_model()\n",
    "\n",
    "    print(\"Models initialized\")\n",
    "\n",
    "    # extract features\n",
    "    rgb_features = []\n",
    "    for i, clip in enumerate(video_clips):\n",
    "        clip = np.array(clip)\n",
    "        if len(clip) < frame_count:\n",
    "            continue\n",
    "\n",
    "        clip = preprocess_input(clip)\n",
    "        rgb_feature = feature_extractor.predict(clip)[0]\n",
    "        rgb_features.append(rgb_feature)\n",
    "\n",
    "        print(\"Processed clip : \", i)\n",
    "\n",
    "    rgb_features = np.array(rgb_features)\n",
    "    rgb_feature_bag = interpolate(rgb_features, features_per_bag)\n",
    "    \n",
    "    # classify using the trained classifier model\n",
    "    predictions = classifier_model.predict(rgb_feature_bag)\n",
    "\n",
    "    predictions = np.array(predictions).squeeze()\n",
    "\n",
    "    predictions = extrapolate(predictions, num_frames)\n",
    "    \n",
    "    save_path = os.path.join(output_folder,video_name+'.mp4').replace(\"\\\\\",'/')\n",
    "    # visualize predictions\n",
    "    print('Executed Successfully - '+video_name + '.gif saved')\n",
    "    visualize_predictions_full(sample_video_path, predictions, save_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
