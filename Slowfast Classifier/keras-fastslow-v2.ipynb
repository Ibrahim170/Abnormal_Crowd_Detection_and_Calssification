{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T08:05:50.401092Z","iopub.execute_input":"2022-01-11T08:05:50.401597Z","iopub.status.idle":"2022-01-11T08:05:50.415198Z","shell.execute_reply.started":"2022-01-11T08:05:50.401547Z","shell.execute_reply":"2022-01-11T08:05:50.414263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport time\nimport matplotlib.pyplot as plt\nfrom numpy import savez_compressed\nimport math\nfrom collections import Counter\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:50.417972Z","iopub.execute_input":"2022-01-11T08:05:50.418358Z","iopub.status.idle":"2022-01-11T08:05:50.472643Z","shell.execute_reply.started":"2022-01-11T08:05:50.418302Z","shell.execute_reply":"2022-01-11T08:05:50.47121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# device_name = tf.test.gpu_device_name()\n# print('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:50.474581Z","iopub.execute_input":"2022-01-11T08:05:50.474932Z","iopub.status.idle":"2022-01-11T08:05:50.480447Z","shell.execute_reply.started":"2022-01-11T08:05:50.474879Z","shell.execute_reply":"2022-01-11T08:05:50.479093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### num_epochs now = 2\n\nclass ModelConfig:\n    EPOCHS = 10\n    BATCH_SIZE = 4\n    num_frames_per_second = 10\n    SEQUENCE_SIZE = 16\n    H = 256\n    W = 256\n    C = 3\n    TO_GRAY = False\n    overlapping = 0\n    rootdir = \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos\"\n    TRAIN_SAMPLE_NPZ_DIRECTORY = \"./train_npz_files\"\n    TEST_SAMPLE_NPZ_DIRECTORY = \"./test_npz_files\"\n    types = {\"Normal\":0, \"Abnormal\":1}\n    classes = {\"Explosion\":1, 'Burglary':2, 'Fighting':3, 'Assault':4, 'Arrest':5, 'Arson':6, 'Abuse':7}\n    extension = \"mp4\"\n    NUM_CLASSES = 8\n    MODEL_WEIGHTS_DIRECTORY = \"./model_weights\"\n    COMBINE_MODEL_PATH = \"combined_model_weights.hdf5\"\n    GENERATOR_MODEL_PATH = \"generator_model_weights.hdf5\"\n    DISCRIMINATOR_MODEL_PATH = \"discriminator_model_weights.hdf5\"\n    CLASSIFIER_MODEL_PATH = \"classifier_model_weights.hdf5\"\n    AUTOENCODER_MODEL_PATH = \"autoencoder_model.hdf5\"\n    \n    NUM_SEGMENTS = 10\n    DIFF_BETWEEN_SEGMENTS = 5\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:51.043348Z","iopub.execute_input":"2022-01-11T08:05:51.043638Z","iopub.status.idle":"2022-01-11T08:05:51.054776Z","shell.execute_reply.started":"2022-01-11T08:05:51.043609Z","shell.execute_reply":"2022-01-11T08:05:51.053099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)\nos.mkdir(ModelConfig.TEST_SAMPLE_NPZ_DIRECTORY)\nos.mkdir(ModelConfig.MODEL_WEIGHTS_DIRECTORY)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:51.388835Z","iopub.execute_input":"2022-01-11T08:05:51.389126Z","iopub.status.idle":"2022-01-11T08:05:51.407352Z","shell.execute_reply.started":"2022-01-11T08:05:51.389095Z","shell.execute_reply":"2022-01-11T08:05:51.405939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_video_times(cap):\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    duration = frame_count / fps\n\n    print('fps = ' + str(fps))\n    print('number of frames = ' + str(frame_count))\n    print('duration (S) = ' + str(duration))\n    minutes = int(duration / 60)\n    seconds = duration % 60\n    print('duration (M:S) = ' + str(minutes) + ':' + str(seconds))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:52.682361Z","iopub.execute_input":"2022-01-11T08:05:52.682752Z","iopub.status.idle":"2022-01-11T08:05:52.689433Z","shell.execute_reply.started":"2022-01-11T08:05:52.682703Z","shell.execute_reply":"2022-01-11T08:05:52.688432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image_black_background(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n    hh, ww = thresh.shape\n    thresh[hh:hh, 0:ww] = 0\n    white = np.where(thresh == 255)\n    \n    if len(white[0]) <= 1 or len(white[1]) <= 1:\n        return None\n    \n    xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n    crop = img[ymin:ymax, xmin:xmax]\n    \n    if (crop.shape[0] < img.shape[0]/2) and (crop.shape[1] < img.shape[1]/2):\n        return None\n    return crop","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:52.946194Z","iopub.execute_input":"2022-01-11T08:05:52.94648Z","iopub.status.idle":"2022-01-11T08:05:52.958278Z","shell.execute_reply.started":"2022-01-11T08:05:52.94645Z","shell.execute_reply":"2022-01-11T08:05:52.957297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SaveVideo2Npz(file_path, npz_directory, resize=(ModelConfig.H, ModelConfig.W), \n                  num_target_frames=ModelConfig.SEQUENCE_SIZE, overlapping=0):\n\n    cap = cv2.VideoCapture(file_path)\n    file_name = file_path.split('/')[-1]\n    file_name = file_name.split('.')[0]\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    len_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    cap.release()\n    \n    skip_length = int((len_frames-(ModelConfig.NUM_SEGMENTS*ModelConfig.DIFF_BETWEEN_SEGMENTS)) / ModelConfig.SEQUENCE_SIZE)   \n           \n    segments_path_list = []\n    frames = []\n    try:        \n        for seg_num in range(ModelConfig.NUM_SEGMENTS):\n            cap_v = cv2.VideoCapture(file_path)\n            len_frames = int(cap_v.get(cv2.CAP_PROP_FRAME_COUNT))            \n            next_index = seg_num*ModelConfig.DIFF_BETWEEN_SEGMENTS\n            first_segt = True\n            index = 0\n            while index < len_frames:\n                _, frame = cap_v.read()              \n                \n                if index == next_index:\n                    next_index = index+skip_length\n                \n                    #frame = crop_image_black_background(frame)\n                    #if frame is None or (frame.shape[0] <= 0 or frame.shape[1] <= 0):\n                    #    continue\n                    \n                    frame = cv2.resize(frame, resize, interpolation=cv2.INTER_AREA)           \n                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                    frame = np.array(frame, dtype=np.float32)\n                    frame /= 255.0\n                    frames.append(frame)\n                index+=1\n                \n            cap_v.release()\n            segments_path = os.path.join(npz_directory, file_name + \"_{}.npz\".format(seg_num))\n            if len(frames) > ModelConfig.SEQUENCE_SIZE:\n                frames = frames[(len(frames)-ModelConfig.SEQUENCE_SIZE):]\n                \n            #print(np.array(frames).shape)\n            savez_compressed(segments_path, np.array(frames))\n            frames.clear()\n            segments_path_list.append(segments_path)     \n    except Exception as e:\n        print(e)\n         \n    return np.array(segments_path_list), fps","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:53.350586Z","iopub.execute_input":"2022-01-11T08:05:53.351031Z","iopub.status.idle":"2022-01-11T08:05:53.365806Z","shell.execute_reply.started":"2022-01-11T08:05:53.35096Z","shell.execute_reply":"2022-01-11T08:05:53.364582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skip_files = [\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary064_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Explosion/Explosion046_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest047_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Fighting/Fighting041_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arson/Arson019_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_940_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary095_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_935_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Normal-Videos-Part-1/Normal_Videos_924_x264.mp4\",\n#     \"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-1/Arrest/Arrest049_x264.mp4\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:53.557049Z","iopub.execute_input":"2022-01-11T08:05:53.557351Z","iopub.status.idle":"2022-01-11T08:05:53.562778Z","shell.execute_reply.started":"2022-01-11T08:05:53.557321Z","shell.execute_reply":"2022-01-11T08:05:53.561779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# segments, _ = SaveVideo2Npz(\"../input/crimeucfdataset/Anomaly_Dataset/Anomaly_Videos/Anomaly-Videos-Part-2/Burglary/Burglary001_x264.mp4\",\n#                             npz_directory=ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY,\n#                             overlapping=ModelConfig.overlapping)\n\n# print(segments)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:54.277002Z","iopub.execute_input":"2022-01-11T08:05:54.277314Z","iopub.status.idle":"2022-01-11T08:05:54.28124Z","shell.execute_reply.started":"2022-01-11T08:05:54.277282Z","shell.execute_reply":"2022-01-11T08:05:54.280476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_npz_file(file_path):\n    dict_data = np.load(file_path)\n    data = dict_data['arr_0']\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:54.776591Z","iopub.execute_input":"2022-01-11T08:05:54.776867Z","iopub.status.idle":"2022-01-11T08:05:54.782709Z","shell.execute_reply.started":"2022-01-11T08:05:54.776838Z","shell.execute_reply":"2022-01-11T08:05:54.781797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = read_npz_file(\"./npz_files/Burglary001_x264_0.npz\")\n# plt.imshow(X[20])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:56.524267Z","iopub.execute_input":"2022-01-11T08:05:56.524521Z","iopub.status.idle":"2022-01-11T08:05:56.528535Z","shell.execute_reply.started":"2022-01-11T08:05:56.524495Z","shell.execute_reply":"2022-01-11T08:05:56.527604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read_npz_file(\"./npz_files/Burglary008_x264_0.npz\").shape","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:56.79198Z","iopub.execute_input":"2022-01-11T08:05:56.792636Z","iopub.status.idle":"2022-01-11T08:05:56.797155Z","shell.execute_reply.started":"2022-01-11T08:05:56.792596Z","shell.execute_reply":"2022-01-11T08:05:56.796388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_npz_directory(directorty_path):\n    for root_f in os.listdir(directorty_path):\n        f1 = os.path.join(directorty_path, root_f)\n        for sub_f in os.listdir(f1):\n            os.remove(os.path.join(f1, sub_f))\n        \nclear_npz_directory(ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)     \n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:05:59.426782Z","iopub.execute_input":"2022-01-11T08:05:59.427118Z","iopub.status.idle":"2022-01-11T08:05:59.534727Z","shell.execute_reply.started":"2022-01-11T08:05:59.427082Z","shell.execute_reply":"2022-01-11T08:05:59.53378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfile_name_list = []\nfile_path_list = []\nfile_type_list = []\nfile_class_list = []\nfile_npy_path_list = []\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:00.141497Z","iopub.execute_input":"2022-01-11T08:06:00.141796Z","iopub.status.idle":"2022-01-11T08:06:00.1464Z","shell.execute_reply.started":"2022-01-11T08:06:00.141744Z","shell.execute_reply":"2022-01-11T08:06:00.145366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dataset_df():\n    global file_name_list \n    global file_path_list\n    global file_type_list \n    global file_class_list \n    global file_npy_path_list\n\n    file_name_list.clear()\n    file_path_list.clear()\n    file_type_list.clear()\n    file_class_list.clear()\n    file_npy_path_list.clear()\n\n\n    for root, subdirs, files in os.walk(ModelConfig.rootdir):\n        for filename in files:\n            if filename.split('.')[-1] != ModelConfig.extension:\n                continue\n\n            file_path = os.path.join(root, filename)\n            file_name = filename.split('.')[0]\n            \n            if file_path in skip_files:\n                continue\n            \n            file_name_list.append(file_name)\n            file_path_list.append(file_path)\n            file_class = file_path.split('/')[-2]\n            #print(file_class)\n            if file_class in ModelConfig.classes.keys():\n                file_type_list.append(ModelConfig.types[\"Abnormal\"])\n                file_class_list.append(ModelConfig.classes[file_class])\n            else:\n                file_type_list.append(ModelConfig.types[\"Normal\"])\n                file_class_list.append(ModelConfig.types[\"Normal\"])\n\n            #npy_path = Save2Npy(file_path, file_name, Config.save_npy_dir)\n            #file_npy_path_list.append(npy_path)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:00.352503Z","iopub.execute_input":"2022-01-11T08:06:00.352831Z","iopub.status.idle":"2022-01-11T08:06:00.362375Z","shell.execute_reply.started":"2022-01-11T08:06:00.352796Z","shell.execute_reply":"2022-01-11T08:06:00.3613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_dataset_df()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:05.265481Z","iopub.execute_input":"2022-01-11T08:06:05.265782Z","iopub.status.idle":"2022-01-11T08:06:05.351951Z","shell.execute_reply.started":"2022-01-11T08:06:05.265747Z","shell.execute_reply":"2022-01-11T08:06:05.351276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(file_path_list), len(file_name_list), len(file_type_list), len(file_class_list)#, len(file_npy_path_list)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:06.882368Z","iopub.execute_input":"2022-01-11T08:06:06.883167Z","iopub.status.idle":"2022-01-11T08:06:06.890258Z","shell.execute_reply.started":"2022-01-11T08:06:06.883122Z","shell.execute_reply":"2022-01-11T08:06:06.889388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#dataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list, file_npy_path_list)),\n#                          columns =['file_name', 'file_path', 'file_type', 'file_class', 'npy_file_path'])\n\ndataset_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list)),\n                          columns =['file_name', 'file_path', 'file_type', 'file_class'])\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:07.170683Z","iopub.execute_input":"2022-01-11T08:06:07.171541Z","iopub.status.idle":"2022-01-11T08:06:07.19908Z","shell.execute_reply.started":"2022-01-11T08:06:07.1715Z","shell.execute_reply":"2022-01-11T08:06:07.197971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:08.423682Z","iopub.execute_input":"2022-01-11T08:06:08.423997Z","iopub.status.idle":"2022-01-11T08:06:08.45741Z","shell.execute_reply.started":"2022-01-11T08:06:08.423961Z","shell.execute_reply":"2022-01-11T08:06:08.456301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df[\"file_class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:09.735559Z","iopub.execute_input":"2022-01-11T08:06:09.736566Z","iopub.status.idle":"2022-01-11T08:06:09.752745Z","shell.execute_reply.started":"2022-01-11T08:06:09.736505Z","shell.execute_reply":"2022-01-11T08:06:09.751997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport random \n\nn = random.randint(0, len(dataset_df))\nrandomlist = random.sample(range(0, len(dataset_df)), len(dataset_df)) \nval_size = 0.1\nval_size = int(len(dataset_df) * val_size)\nval_idx = randomlist[:val_size]\ntrain_idx = randomlist[val_size:]\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:14.004544Z","iopub.execute_input":"2022-01-11T08:06:14.005814Z","iopub.status.idle":"2022-01-11T08:06:14.017802Z","shell.execute_reply.started":"2022-01-11T08:06:14.005769Z","shell.execute_reply":"2022-01-11T08:06:14.016569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_df = dataset_df.iloc[val_idx].reset_index()\ntrain_df = dataset_df.iloc[train_idx].reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:15.662768Z","iopub.execute_input":"2022-01-11T08:06:15.663625Z","iopub.status.idle":"2022-01-11T08:06:15.674917Z","shell.execute_reply.started":"2022-01-11T08:06:15.663588Z","shell.execute_reply":"2022-01-11T08:06:15.674284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"train_df.csv\")\nvalidation_df.to_csv(\"validation_df.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:16.028879Z","iopub.execute_input":"2022-01-11T08:06:16.029157Z","iopub.status.idle":"2022-01-11T08:06:16.044078Z","shell.execute_reply.started":"2022-01-11T08:06:16.029128Z","shell.execute_reply":"2022-01-11T08:06:16.043197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_dataset(dataframe, npz_directory):\n    global file_path_list\n    global file_type_list \n    global file_class_list \n    global file_npy_path_list\n\n    file_name_list.clear()\n    file_path_list.clear()\n    file_type_list.clear()\n    file_class_list.clear()\n    file_npy_path_list.clear()\n\n    \n    for c in np.unique(dataset_df[\"file_class\"]):    \n        os.makedirs(os.path.join(npz_directory, str(c)), exist_ok=True)\n        \n    path_list = []\n    class_list = []\n    for index, row in dataframe.iterrows():\n        print(str(index), \" Done\")\n        sample_file_path = row[\"file_path\"]\n        sample_npz_directory = os.path.join(npz_directory, str(row[\"file_class\"]))\n        segments, _ = SaveVideo2Npz(sample_file_path, sample_npz_directory)\n        for seg_path in segments:\n            file_name_list.append(row[\"file_name\"])\n            file_path_list.append(row[\"file_path\"])\n            file_type_list.append(row[\"file_type\"])\n            file_class_list.append(row[\"file_class\"])\n            file_npy_path_list.append(seg_path)\n            ","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:20.28761Z","iopub.execute_input":"2022-01-11T08:06:20.288323Z","iopub.status.idle":"2022-01-11T08:06:20.298388Z","shell.execute_reply.started":"2022-01-11T08:06:20.288273Z","shell.execute_reply":"2022-01-11T08:06:20.297495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_dataset(train_df, ModelConfig.TRAIN_SAMPLE_NPZ_DIRECTORY)\n\n\ntrain_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list, file_npy_path_list)),\n                        columns =['file_name', 'file_path', 'file_type', 'file_class', 'file_npy_path_list'])\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-01-11T08:06:20.299995Z","iopub.execute_input":"2022-01-11T08:06:20.300419Z","iopub.status.idle":"2022-01-11T08:06:32.203366Z","shell.execute_reply.started":"2022-01-11T08:06:20.300389Z","shell.execute_reply":"2022-01-11T08:06:32.201796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_dataset(validation_df, ModelConfig.TEST_SAMPLE_NPZ_DIRECTORY)\n\n\nvalidation_df = pd.DataFrame(list(zip(file_name_list, file_path_list, file_type_list, file_class_list, file_npy_path_list)),\n                        columns =['file_name', 'file_path', 'file_type', 'file_class', 'file_npy_path_list'])\n\nvalidation_df","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:12:44.127997Z","iopub.execute_input":"2022-01-10T15:12:44.128681Z","iopub.status.idle":"2022-01-10T15:28:02.590293Z","shell.execute_reply.started":"2022-01-10T15:12:44.128631Z","shell.execute_reply":"2022-01-10T15:28:02.58929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-09T18:03:34.68724Z","iopub.execute_input":"2022-01-09T18:03:34.688066Z","iopub.status.idle":"2022-01-09T18:03:34.698034Z","shell.execute_reply.started":"2022-01-09T18:03:34.688013Z","shell.execute_reply":"2022-01-09T18:03:34.697103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 classes=np.unique(train_df[\"file_class\"]),\n                                                 y=train_df[\"file_class\"])\n\nclass_weights = {k: v for k,v in enumerate(class_weights)}\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:34.294219Z","iopub.execute_input":"2022-01-10T15:31:34.294601Z","iopub.status.idle":"2022-01-10T15:31:34.310374Z","shell.execute_reply.started":"2022-01-10T15:31:34.294564Z","shell.execute_reply":"2022-01-10T15:31:34.309148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\n\n\nclass CustomDataGen(tf.keras.utils.Sequence):\n    def __init__(self, dataset_df, X_col, y_col, shuffle=True):\n        self.batch_size = ModelConfig.BATCH_SIZE\n        self.dataset_df = dataset_df\n        self.X_col = X_col\n        self.y_col = y_col\n        self.shuffle = shuffle\n        self.classes = np.unique(self.dataset_df[self.y_col])\n        self.num_classes =  len(self.classes)\n        self.X_path, self.Y_dict = self.search_data() \n        self.print_stats()\n        self.on_epoch_end()\n        return None\n        \n    def search_data(self):\n        X_path = []\n        Y_dict = {}\n        one_hots = to_categorical(self.dataset_df[self.y_col], self.num_classes)\n        for index in range(len(self.dataset_df)):\n            X_path.append(self.dataset_df.at[index, self.X_col])\n            Y_dict[X_path[-1]] = one_hots[index]\n        return X_path, Y_dict\n    \n    def print_stats(self):\n        self.n_files = len(self.X_path)\n        self.indexes = np.arange(len(self.X_path))\n        np.random.shuffle(self.indexes)\n        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.num_classes))\n    \n    def __len__(self):\n        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n        return int(steps_per_epoch)\n\n    def __getitem__(self, index):\n        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_path = [self.X_path[k] for k in batch_indexs]\n        batch_x, batch_y = self.data_generation(batch_path)               \n        return batch_x, batch_y\n    \n    def get_mini_batch(self, index):\n        return self.__getitem__(index)\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def data_generation(self, batch_path):\n        batch_x = [self.load_data(x) for x in batch_path]\n        batch_y = [self.Y_dict[x] for x in batch_path]\n\n        batch_x = np.array(batch_x)\n        batch_y = np.array(batch_y)\n        return batch_x, batch_y\n    \n    def load_data(self, path):\n        sample = read_npz_file(path)\n        return sample\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:42.939731Z","iopub.execute_input":"2022-01-10T15:31:42.940039Z","iopub.status.idle":"2022-01-10T15:31:42.95828Z","shell.execute_reply.started":"2022-01-10T15:31:42.940008Z","shell.execute_reply":"2022-01-10T15:31:42.957377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = CustomDataGen(train_df,\n                           X_col=\"file_npy_path_list\",\n                           y_col=\"file_class\",\n                           shuffle=True)\n\n\n#train_gen.get_mini_batch(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:45.393436Z","iopub.execute_input":"2022-01-10T15:31:45.39374Z","iopub.status.idle":"2022-01-10T15:31:45.441236Z","shell.execute_reply.started":"2022-01-10T15:31:45.393709Z","shell.execute_reply":"2022-01-10T15:31:45.440225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_gen = CustomDataGen(validation_df,\n                               X_col=\"file_npy_path_list\",\n                               y_col=\"file_class\",\n                               shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:45.956848Z","iopub.execute_input":"2022-01-10T15:31:45.95767Z","iopub.status.idle":"2022-01-10T15:31:45.967916Z","shell.execute_reply.started":"2022-01-10T15:31:45.957624Z","shell.execute_reply":"2022-01-10T15:31:45.96703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv3D, BatchNormalization, ReLU, Add, MaxPool3D, GlobalAveragePooling3D, Concatenate, Dropout, Dense, Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Input\n\n\ndef Conv_BN_ReLU(planes, kernel_size, strides=(1, 1, 1), padding='same', use_bias=False):\n    return Sequential([\n        Conv3D(planes, kernel_size, strides=strides, padding=padding, use_bias=use_bias),\n        BatchNormalization(),\n        ReLU()\n    ])\n\n\ndef bottleneck(x, planes, stride=1, downsample=None, head_conv=1, use_bias=False):\n    residual = x\n    if head_conv == 1:\n        x = Conv_BN_ReLU(planes, kernel_size=1, use_bias=use_bias)(x)\n    elif head_conv == 3:\n        x = Conv_BN_ReLU(planes, kernel_size=(3, 1, 1), use_bias=use_bias)(x)\n    else:\n        raise ValueError('Unsupported head_conv!!!')\n    x = Conv_BN_ReLU(planes, kernel_size=(1, 3, 3), strides=(1, stride, stride), use_bias=use_bias)(x)\n    x = Conv3D(planes*4, kernel_size=1, use_bias=use_bias)(x)\n    x = BatchNormalization()(x)\n    if downsample is not None:\n        residual = downsample(residual)\n    x = Add()([x, residual])\n    x = ReLU()(x)\n    return x\n\ndef datalayer(x, stride):\n    return x[:, ::stride, :, :, :]\n\ndef SlowFast_body(inputs, layers, block, num_classes, dropout=0.5):\n    inputs_fast = Lambda(datalayer, name='data_fast', arguments={'stride':2})(inputs)\n    inputs_slow = Lambda(datalayer, name='data_slow', arguments={'stride':16})(inputs)\n    fast, lateral = Fast_body(inputs_fast, layers, block)\n    slow = Slow_body(inputs_slow, lateral, layers, block)\n    x = Concatenate()([slow, fast])\n    x = Dropout(dropout)(x)\n    out = Dense(num_classes, activation='softmax')(x)\n    return Model(inputs, out)\n\n\n\ndef Fast_body(x, layers, block):\n    fast_inplanes = 8\n    lateral = []\n    x = Conv_BN_ReLU(8, kernel_size=(5, 7, 7), strides=(1, 2, 2))(x)\n    x = MaxPool3D(pool_size=(1, 3, 3), strides=(1, 2, 2), padding='same')(x)\n    lateral_p1 = Conv3D(8*2, kernel_size=(5, 1, 1), strides=(8, 1, 1), padding='same', use_bias=False)(x)\n    lateral.append(lateral_p1)\n    x, fast_inplanes = make_layer_fast(x, block, 8, layers[0], head_conv=3, fast_inplanes=fast_inplanes)\n    lateral_res2 = Conv3D(32*2, kernel_size=(5, 1, 1), strides=(8, 1, 1), padding='same', use_bias=False)(x)\n    lateral.append(lateral_res2)\n    x, fast_inplanes = make_layer_fast(x, block, 16, layers[1], stride=2, head_conv=3, fast_inplanes=fast_inplanes)\n    lateral_res3 = Conv3D(64*2, kernel_size=(5, 1, 1), strides=(8, 1, 1), padding='same', use_bias=False)(x)\n    lateral.append(lateral_res3)\n    x, fast_inplanes = make_layer_fast(x, block, 32, layers[2], stride=2, head_conv=3, fast_inplanes=fast_inplanes)\n    lateral_res4 = Conv3D(128*2, kernel_size=(5, 1, 1), strides=(8, 1, 1), padding='same', use_bias=False)(x)\n    lateral.append(lateral_res4)\n    x, fast_inplanes = make_layer_fast(x, block, 64, layers[3], stride=2, head_conv=3, fast_inplanes=fast_inplanes)\n    x = GlobalAveragePooling3D()(x)\n    return x, lateral\n\ndef Slow_body(x, lateral, layers, block):\n    slow_inplanes = 64 + 64//8*2\n    x = Conv_BN_ReLU(64, kernel_size=(1, 7, 7), strides=(1, 2, 2))(x)\n    x = MaxPool3D(pool_size=(1, 3, 3), strides=(1, 2, 2), padding='same')(x)\n    x = Concatenate()([x, lateral[0]])\n    x, slow_inplanes = make_layer_slow(x, block, 64, layers[0], head_conv=1, slow_inplanes=slow_inplanes)\n    x = Concatenate()([x, lateral[1]])\n    x, slow_inplanes = make_layer_slow(x, block, 128, layers[1], stride=2, head_conv=1, slow_inplanes=slow_inplanes)\n    x = Concatenate()([x, lateral[2]])\n    x, slow_inplanes = make_layer_slow(x, block, 256, layers[2], stride=2, head_conv=1, slow_inplanes=slow_inplanes)\n    x = Concatenate()([x, lateral[3]])\n    x, slow_inplanes = make_layer_slow(x, block, 512, layers[3], stride=2, head_conv=1, slow_inplanes=slow_inplanes)\n    x = GlobalAveragePooling3D()(x)\n    return x\n\n\ndef make_layer_fast(x, block, planes, blocks, stride=1, head_conv=1, fast_inplanes=8, block_expansion=4):\n    downsample = None\n    if stride != 1 or fast_inplanes != planes * block_expansion:\n        downsample = Sequential([\n            Conv3D(planes*block_expansion, kernel_size=1, strides=(1, stride, stride), use_bias=False),\n            BatchNormalization()\n        ])\n    fast_inplanes = planes * block_expansion\n    x = block(x, planes, stride, downsample=downsample, head_conv=head_conv)\n    for _ in range(1, blocks):\n        x = block(x, planes, head_conv=head_conv)\n    return x, fast_inplanes\n\ndef make_layer_slow(x, block, planes, blocks, stride=1, head_conv=1, slow_inplanes=80, block_expansion=4):\n    downsample = None\n    if stride != 1 or slow_inplanes != planes * block_expansion:\n        downsample = Sequential([\n            Conv3D(planes*block_expansion, kernel_size=1, strides = (1, stride, stride), use_bias=False),\n            BatchNormalization()\n        ])\n    x = block(x, planes, stride, downsample, head_conv=head_conv)\n    for _ in range(1, blocks):\n        x = block(x, planes, head_conv=head_conv)\n    slow_inplanes = planes * block_expansion + planes * block_expansion//8*2\n    return x, slow_inplanes\n\n\n\n\ndef resnet50(inputs, **kwargs):\n    model = SlowFast_body(inputs, [3, 4, 6, 3], bottleneck, **kwargs)\n    return model\n\ndef resnet101(inputs, **kwargs):\n    model = SlowFast_body(inputs, [3, 4, 23, 3], bottleneck, **kwargs)\n    return model\n\ndef resnet152(inputs, **kwargs):\n    model = SlowFast_body(inputs, [3, 8, 36, 3], bottleneck, **kwargs)\n    return model\n\ndef resnet200(inputs, **kwargs):\n    model = Slow_body(inputs, [3, 24, 36, 3], bottleneck, **kwargs)\n    return model\n\n\n\nnetwork = {\n    'resnet50':resnet50,\n    'resnet101':resnet101,\n    'resnet152':resnet152,\n    'resnet200':resnet200\n}\n\n\nx = Input(shape=(None, None, None, 3))\nmodel = resnet50(x, num_classes=15)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:55.677Z","iopub.execute_input":"2022-01-10T15:31:55.677295Z","iopub.status.idle":"2022-01-10T15:31:58.988278Z","shell.execute_reply.started":"2022-01-10T15:31:55.677266Z","shell.execute_reply":"2022-01-10T15:31:58.987319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = SlowFast_Network(clip_shape=[ModelConfig.SEQUENCE_SIZE,ModelConfig.H, ModelConfig.W, ModelConfig.C],\n#                         num_class=ModelConfig.NUM_CLASSES,alpha=8,beta=1/8,tau=16,method='T_conv')\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:58.989844Z","iopub.execute_input":"2022-01-10T15:31:58.990376Z","iopub.status.idle":"2022-01-10T15:31:59.123407Z","shell.execute_reply.started":"2022-01-10T15:31:58.990333Z","shell.execute_reply":"2022-01-10T15:31:59.122557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nX_input = Input(shape=((ModelConfig.SEQUENCE_SIZE, ModelConfig.H, ModelConfig.W, ModelConfig.C)))\nclf  = resnet50(X_input, \n                            num_classes=ModelConfig.NUM_CLASSES)\n#opt = Adam(learning_rate=1e-3, beta_1 = 0.9, decay = 1e-4)\nopt = Adam()\nclf.compile(optimizer='adam',\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])   ","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:31:59.124655Z","iopub.execute_input":"2022-01-10T15:31:59.124948Z","iopub.status.idle":"2022-01-10T15:32:02.825585Z","shell.execute_reply.started":"2022-01-10T15:31:59.124905Z","shell.execute_reply":"2022-01-10T15:32:02.824845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install livelossplot","metadata":{"execution":{"iopub.status.busy":"2022-01-10T15:32:02.827084Z","iopub.execute_input":"2022-01-10T15:32:02.827898Z","iopub.status.idle":"2022-01-10T15:32:13.448817Z","shell.execute_reply.started":"2022-01-10T15:32:02.827859Z","shell.execute_reply":"2022-01-10T15:32:13.447708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom livelossplot import PlotLossesKeras\n\n\nmodel_weights_file_path = os.path.join(ModelConfig.MODEL_WEIGHTS_DIRECTORY, ModelConfig.CLASSIFIER_MODEL_PATH)\ncheckpoint = ModelCheckpoint(filepath=model_weights_file_path, monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode=\"max\", save_weights_only=True)\nearly_stopping = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, patience=20)\nlr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=0, mode='max', min_delta=0.0001, cooldown=0, min_lr=0)\nplotlosses = PlotLossesKeras()\n\ncall_backs = [checkpoint, early_stopping, lr_reduce, plotlosses]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:41:32.878036Z","iopub.execute_input":"2022-01-10T16:41:32.878365Z","iopub.status.idle":"2022-01-10T16:41:32.887646Z","shell.execute_reply.started":"2022-01-10T16:41:32.878334Z","shell.execute_reply":"2022-01-10T16:41:32.886733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #with tf.device(device_name):\n# history = clf.fit(train_gen, \n#                     validation_data=validation_gen,\n#                     epochs=ModelConfig.EPOCHS, \n#                     callbacks=call_backs, \n#                     class_weight=class_weights,\n#                     verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T16:41:33.975964Z","iopub.execute_input":"2022-01-10T16:41:33.97627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clf_model.evaluate(train_gen)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:58:10.183433Z","iopub.status.idle":"2022-01-09T07:58:10.184013Z","shell.execute_reply.started":"2022-01-09T07:58:10.183755Z","shell.execute_reply":"2022-01-09T07:58:10.183782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X, y = train_gen.get_mini_batch(288)\n# print(X[0][-1])\n# read_npz_file(X[0][-1]).shape","metadata":{"execution":{"iopub.status.busy":"2022-01-07T20:36:18.666996Z","iopub.status.idle":"2022-01-07T20:36:18.667532Z","shell.execute_reply.started":"2022-01-07T20:36:18.667302Z","shell.execute_reply":"2022-01-07T20:36:18.667327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}